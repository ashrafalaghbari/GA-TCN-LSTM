{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ashrafalaghbari/Mutivariate-long-term-forecasting-of-oil-production/blob/main/multivariate_model_multistep.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "x1LrkoSv4cc7",
        "outputId": "4b1e7619-44b3-4bad-90c0-5a6763d34474"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "IPython.notebook.set_autosave_interval(60000)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Autosaving every 60 seconds\n"
          ]
        }
      ],
      "source": [
        "%autosave 60"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "XxzUA1Pg4iEU"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Activation, Dropout\n",
        "from keras.layers import LSTM\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from math import sqrt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I6ZrWV9NpfPM",
        "outputId": "ab678870-cdbe-49af-adc4-0c81e7bff1bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Jan  7 16:07:53 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   56C    P0    28W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Hu7vsRejtR_4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d4495e3-3e52-4e19-cd70-762ebcf22765"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ],
      "source": [
        "# check if GPU is utilized \n",
        "device_name = tf.config.experimental.list_physical_devices()[-1][-1]\n",
        "if device_name != 'GPU':\n",
        "    raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(tf.test.gpu_device_name()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "lVMp6qZiT9gO"
      },
      "outputs": [],
      "source": [
        "# convert series to supervised learning\n",
        "def series_to_supervised(data, columns, n_in=1, n_out=1, dropnan=True):\n",
        "    n_vars = 1 if type(data) is list else data.shape[1]\n",
        "    df = pd.DataFrame(data)\n",
        "    cols, names = list(), list()\n",
        "    # input sequence (t-n, ... t-1)\n",
        "    for i in range(n_in, 0, -1):\n",
        "        cols.append(df.shift(i))\n",
        "        names += [('%s(t-%d)' % (columns[j], i)) for j in range(n_vars)]\n",
        "        # forecast sequence (t, t+1, ... t+n)\n",
        "    for i in range(0, n_out):\n",
        "        cols.append(df.shift(-i))\n",
        "        if i == 0:\n",
        "            names += [('%s(t)' % (columns[j])) for j in range(n_vars)]\n",
        "        else:\n",
        "            names += [('%s(t+%d)' % (columns[j], i)) for j in range(n_vars)]\n",
        "    # put it all together\n",
        "    agg = pd.concat(cols, axis=1)\n",
        "    agg.columns = names\n",
        "    # drop rows with NaN values\n",
        "    if dropnan:\n",
        "        agg.dropna(inplace=True)\n",
        "    return agg\n",
        "\n",
        "# scale train and test data to [0, 1]\n",
        "def scale(train, test):\n",
        "\t# fit scaler\n",
        "\tscaler = MinMaxScaler(feature_range=(0, 1))\n",
        "\tscaler = scaler.fit(train)\n",
        "\t# transform train\n",
        "\ttrain = train.reshape(train.shape[0], train.shape[1])\n",
        "\ttrain_scaled = scaler.transform(train)\n",
        "\t# transform test\n",
        "\ttest = test.reshape(test.shape[0], test.shape[1])\n",
        "\ttest_scaled = scaler.transform(test)\n",
        "\treturn scaler, train_scaled, test_scaled\n",
        "\n",
        "\n",
        "# inverse differencing\n",
        "def inverse_difference(history, interval=1):\n",
        "\treturn history[-len(test_scaled)-interval:-interval]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "sX-FCHP3Hy7E"
      },
      "outputs": [],
      "source": [
        "#Evaluation metrics\n",
        "# compute RMSPE\n",
        "def RMSPE(x,y):\n",
        "\tresult=0\n",
        "\tfor i in range(len(x)):\n",
        "\t\tresult += ((x[i]-y[i])/x[i])**2\n",
        "\tresult /= len(x)\n",
        "\tresult = sqrt(result)\n",
        "\tresult *= 100\n",
        "\treturn result\n",
        "\n",
        "# compute MAPE\n",
        "def MAPE(x,y):\n",
        "\tresult=0\n",
        "\tfor i in range(len(x)):\n",
        "\t\tresult += abs((x[i]-y[i])/x[i])\n",
        "\tresult /= len(x)\n",
        "\tresult *= 100\n",
        "\treturn result\n",
        "\n",
        "# compute wMAPE weighted absolute percentage error\n",
        "def wMAPE(actual, predicted): \n",
        "    result_nom = 0\n",
        "    result_deno = 0\n",
        "    for i in range(len(actual)):\n",
        "        result_nom +=  abs(actual[i] - predicted[i])\n",
        "        result_deno +=  abs(actual[i]) \n",
        "    result = result_nom/result_deno\n",
        "    return result *100\n",
        "\n",
        "def SMAPE(actual, predicted): #adjusted MEAN ABSOLUTE PERCENTAGE ERROR (SMAPE)\n",
        "    result = 0\n",
        "    for i in range(len(actual)):\n",
        "        result += abs(actual[i] - predicted[i])/(abs(actual[i]) + abs(predicted[i]))\n",
        "    result = 2* result/ len(actual) \n",
        "    return result * 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RNb6b1BBNzD9"
      },
      "outputs": [],
      "source": [
        "colum = pd.read_csv('/content/drive/MyDrive/volve_production_data/model.csv')\n",
        "colum.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "lu0tOwl84Xln"
      },
      "outputs": [],
      "source": [
        "#load dataset\n",
        "series = pd.read_csv('/content/drive/MyDrive/volve_production_data/model.csv',\n",
        "                     usecols=[\"DATEPRD\",'AVG_CHOKE_SIZE_P','AVG_DOWNHOLE_PRESSURE','AVG_DOWNHOLE_TEMPERATURE',\n",
        "                              'ON_STREAM_HRS','AVG_WHP_P','AVG_WHT_P','F_4_BORE_WI_VOL','F_5_BORE_WI_VOL',\n",
        "                              'DP_CHOKE_SIZE', 'BORE_GAS_VOL', 'BORE_WAT_VOL',\n",
        "                              \"BORE_OIL_VOL\"],\n",
        "                  parse_dates=[\"DATEPRD\"], index_col=\"DATEPRD\")\n",
        "#change the order of BORE_OIL_VOL\n",
        "# series =series[[\"ON_STREAM_HRS\",'BORE_GAS_VOL', 'BORE_WAT_VOL','AVG_CHOKE_SIZE_P','F_4_BORE_WI_VOL','F_5_BORE_WI_VOL',\n",
        "                # \"BORE_OIL_VOL\"]] # chan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x-eyECzKBiWE"
      },
      "outputs": [],
      "source": [
        "recovery_time  = pd.Series(series.index.values).diff()\n",
        "recovery_time = recovery_time.fillna(pd.Timedelta(days=1))\n",
        "recovery_time = recovery_time.astype('string')\n",
        "recovery_time  = recovery_time.str.extract(r'(\\d+)')\n",
        "recovery_time.index = series.index.values\n",
        "series['recovery_time']  = recovery_time.astype('int')\n",
        "series['recovery_time'] = series['recovery_time'] - 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EAbY5vlkTF2C"
      },
      "outputs": [],
      "source": [
        "shutin_days = pd.Series(index=series.index, dtype='int')\n",
        "count = 0\n",
        "for id,v in enumerate(series[\"ON_STREAM_HRS\"]):\n",
        "    \n",
        "    if v == 0:\n",
        "        shutin_days[id] = 0\n",
        "        count+=1\n",
        "        #continue\n",
        "    else:\n",
        "        shutin_days[id] = count\n",
        "        count = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XH0EYNr5cAO7"
      },
      "outputs": [],
      "source": [
        "series['shutin_days'] = shutin_days"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 614
        },
        "id": "r8IlUXdMZkDf",
        "outputId": "695efaa5-c094-4047-943d-6c5cb5dc87b6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-8a905d29-9ec2-46a8-91f1-849d6e2cd63b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ON_STREAM_HRS</th>\n",
              "      <th>BORE_GAS_VOL</th>\n",
              "      <th>BORE_WAT_VOL</th>\n",
              "      <th>AVG_CHOKE_SIZE_P</th>\n",
              "      <th>F_4_BORE_WI_VOL</th>\n",
              "      <th>F_5_BORE_WI_VOL</th>\n",
              "      <th>BORE_OIL_VOL</th>\n",
              "      <th>recovery_time</th>\n",
              "      <th>shutin_days</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DATEPRD</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2010-08-12</th>\n",
              "      <td>24.00000</td>\n",
              "      <td>1.189315e+07</td>\n",
              "      <td>21979.051263</td>\n",
              "      <td>59.194010</td>\n",
              "      <td>41026.601139</td>\n",
              "      <td>42214.231030</td>\n",
              "      <td>14633.118565</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-08-13</th>\n",
              "      <td>24.00000</td>\n",
              "      <td>1.189629e+07</td>\n",
              "      <td>22027.294110</td>\n",
              "      <td>59.199363</td>\n",
              "      <td>40552.473361</td>\n",
              "      <td>42752.254569</td>\n",
              "      <td>14629.659169</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-08-14</th>\n",
              "      <td>24.00000</td>\n",
              "      <td>1.186412e+07</td>\n",
              "      <td>22003.770218</td>\n",
              "      <td>59.231621</td>\n",
              "      <td>40563.073975</td>\n",
              "      <td>42852.919662</td>\n",
              "      <td>14631.042927</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-08-15</th>\n",
              "      <td>23.75833</td>\n",
              "      <td>1.155754e+07</td>\n",
              "      <td>21382.777218</td>\n",
              "      <td>57.292090</td>\n",
              "      <td>39495.791300</td>\n",
              "      <td>41199.828827</td>\n",
              "      <td>14332.528516</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-08-17</th>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>24883.763848</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-08-20</th>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-08-21</th>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-08-22</th>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-08-23</th>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-08-25</th>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-08-26</th>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-08-27</th>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-08-28</th>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-08-29</th>\n",
              "      <td>20.00833</td>\n",
              "      <td>5.730944e+06</td>\n",
              "      <td>10990.626348</td>\n",
              "      <td>32.318808</td>\n",
              "      <td>26107.755187</td>\n",
              "      <td>22571.624901</td>\n",
              "      <td>7008.798850</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-08-30</th>\n",
              "      <td>24.00000</td>\n",
              "      <td>7.604381e+06</td>\n",
              "      <td>10617.892172</td>\n",
              "      <td>35.227124</td>\n",
              "      <td>25885.183727</td>\n",
              "      <td>27917.465093</td>\n",
              "      <td>9661.778063</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-08-31</th>\n",
              "      <td>24.00000</td>\n",
              "      <td>6.972537e+06</td>\n",
              "      <td>10357.431115</td>\n",
              "      <td>33.087920</td>\n",
              "      <td>25136.342214</td>\n",
              "      <td>24290.501632</td>\n",
              "      <td>8969.835999</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-09-01</th>\n",
              "      <td>21.33333</td>\n",
              "      <td>7.671171e+06</td>\n",
              "      <td>16690.452714</td>\n",
              "      <td>37.381105</td>\n",
              "      <td>24646.917436</td>\n",
              "      <td>27698.373131</td>\n",
              "      <td>9617.560694</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8a905d29-9ec2-46a8-91f1-849d6e2cd63b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8a905d29-9ec2-46a8-91f1-849d6e2cd63b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8a905d29-9ec2-46a8-91f1-849d6e2cd63b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "            ON_STREAM_HRS  BORE_GAS_VOL  BORE_WAT_VOL  AVG_CHOKE_SIZE_P  \\\n",
              "DATEPRD                                                                   \n",
              "2010-08-12       24.00000  1.189315e+07  21979.051263         59.194010   \n",
              "2010-08-13       24.00000  1.189629e+07  22027.294110         59.199363   \n",
              "2010-08-14       24.00000  1.186412e+07  22003.770218         59.231621   \n",
              "2010-08-15       23.75833  1.155754e+07  21382.777218         57.292090   \n",
              "2010-08-17        0.00000  0.000000e+00      0.000000          0.000000   \n",
              "2010-08-20        0.00000  0.000000e+00      0.000000          0.000000   \n",
              "2010-08-21        0.00000  0.000000e+00      0.000000          0.000000   \n",
              "2010-08-22        0.00000  0.000000e+00      0.000000          0.000000   \n",
              "2010-08-23        0.00000  0.000000e+00      0.000000          0.000000   \n",
              "2010-08-25        0.00000  0.000000e+00      0.000000          0.000000   \n",
              "2010-08-26        0.00000  0.000000e+00      0.000000          0.000000   \n",
              "2010-08-27        0.00000  0.000000e+00      0.000000          0.000000   \n",
              "2010-08-28        0.00000  0.000000e+00      0.000000          0.000000   \n",
              "2010-08-29       20.00833  5.730944e+06  10990.626348         32.318808   \n",
              "2010-08-30       24.00000  7.604381e+06  10617.892172         35.227124   \n",
              "2010-08-31       24.00000  6.972537e+06  10357.431115         33.087920   \n",
              "2010-09-01       21.33333  7.671171e+06  16690.452714         37.381105   \n",
              "\n",
              "            F_4_BORE_WI_VOL  F_5_BORE_WI_VOL  BORE_OIL_VOL  recovery_time  \\\n",
              "DATEPRD                                                                     \n",
              "2010-08-12     41026.601139     42214.231030  14633.118565              0   \n",
              "2010-08-13     40552.473361     42752.254569  14629.659169              0   \n",
              "2010-08-14     40563.073975     42852.919662  14631.042927              0   \n",
              "2010-08-15     39495.791300     41199.828827  14332.528516              0   \n",
              "2010-08-17         0.000000     24883.763848      0.000000              1   \n",
              "2010-08-20         0.000000         0.000000      0.000000              2   \n",
              "2010-08-21         0.000000         0.000000      0.000000              0   \n",
              "2010-08-22         0.000000         0.000000      0.000000              0   \n",
              "2010-08-23         0.000000         0.000000      0.000000              0   \n",
              "2010-08-25         0.000000         0.000000      0.000000              1   \n",
              "2010-08-26         0.000000         0.000000      0.000000              0   \n",
              "2010-08-27         0.000000         0.000000      0.000000              0   \n",
              "2010-08-28         0.000000         0.000000      0.000000              0   \n",
              "2010-08-29     26107.755187     22571.624901   7008.798850              0   \n",
              "2010-08-30     25885.183727     27917.465093   9661.778063              0   \n",
              "2010-08-31     25136.342214     24290.501632   8969.835999              0   \n",
              "2010-09-01     24646.917436     27698.373131   9617.560694              0   \n",
              "\n",
              "            shutin_days  \n",
              "DATEPRD                  \n",
              "2010-08-12            0  \n",
              "2010-08-13            0  \n",
              "2010-08-14            0  \n",
              "2010-08-15            0  \n",
              "2010-08-17            0  \n",
              "2010-08-20            0  \n",
              "2010-08-21            0  \n",
              "2010-08-22            0  \n",
              "2010-08-23            0  \n",
              "2010-08-25            0  \n",
              "2010-08-26            0  \n",
              "2010-08-27            0  \n",
              "2010-08-28            0  \n",
              "2010-08-29            9  \n",
              "2010-08-30            0  \n",
              "2010-08-31            0  \n",
              "2010-09-01            0  "
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "series.loc[\"2010-08-12\":\"2010-09-01\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "rEvzyzwpkkLr"
      },
      "outputs": [],
      "source": [
        "column_to_move = series.pop(\"BORE_OIL_VOL\")\n",
        "\n",
        "# insert column with insert(location, column_name, column_value)\n",
        "\n",
        "series.insert(len(series.columns), \"BORE_OIL_VOL\", column_to_move)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PKimF-JdZSUV",
        "outputId": "d3daeb0b-9e2e-4e37-b727-f864bccbeb2f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1844, 12)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "series.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bHnnyU0E1T2",
        "outputId": "d6e72d7e-4fd5-4fe3-e8b4-1f1b14018b5a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ON_STREAM_HRS               0.429017\n",
              "AVG_DOWNHOLE_PRESSURE      -0.514724\n",
              "AVG_DOWNHOLE_TEMPERATURE    0.918395\n",
              "AVG_CHOKE_SIZE_P           -0.067340\n",
              "AVG_WHP_P                   0.247035\n",
              "AVG_WHT_P                   0.426416\n",
              "DP_CHOKE_SIZE               0.048679\n",
              "BORE_GAS_VOL                0.996707\n",
              "BORE_WAT_VOL                0.290599\n",
              "F_4_BORE_WI_VOL             0.516457\n",
              "F_5_BORE_WI_VOL             0.582626\n",
              "BORE_OIL_VOL                1.000000\n",
              "Name: BORE_OIL_VOL, dtype: float64"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "series.corr().iloc[:,-1] #200"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dLBz9GX14-Wi"
      },
      "outputs": [],
      "source": [
        "# Data visulaization and disribution plots for well F-14 after including the injectors\n",
        "data = series.columns\n",
        "\n",
        "# Creating figure with two rows and one column\n",
        "fig, axs = plt.subplots(nrows=len(data), figsize=(17, 28))\n",
        "\n",
        "axs = axs.ravel()\n",
        "\n",
        "for id, column in enumerate(data):\n",
        "\n",
        "    axs[id].plot(series[column])\n",
        "    axs[id].grid(True)\n",
        "    axs[id].legend([column], loc='lower left', fontsize=9, handlelength=0, handletextpad=0, frameon=False)\n",
        "    \n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yuC_Qoqiaq_i"
      },
      "source": [
        "**Multi-output forecasting strategy**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Nq2GI1a0NKYT"
      },
      "outputs": [],
      "source": [
        "# # # convert series to stationary \n",
        "series_diff = series.copy()\n",
        "diff_order = 1\n",
        "series_diff['BORE_OIL_VOL'] = series_diff['BORE_OIL_VOL'].diff(diff_order)\n",
        "# # convert the stationary series to supervise learning\n",
        "timesteps = 10 # lag features\n",
        "steps_ahead = 1\n",
        "series_supervised = series_to_supervised(series_diff, series_diff.columns, n_in=timesteps, n_out=steps_ahead, dropnan=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BPxV4RAJfvsU",
        "outputId": "5a00e4d6-5c68-4e3a-9f6f-20e23d3d5cc8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([13290.87298265, 13287.91677167, 13258.29176374, 13290.24400159,\n",
              "       13301.69145688, 13338.48684889, 13371.82284507, 13101.29809116,\n",
              "       13088.0894889 , 13021.92068139])"
            ]
          },
          "execution_count": 256,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "agg[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "24-lK2pd-1oQ"
      },
      "outputs": [],
      "source": [
        "test_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tMMY-kNyfDat",
        "outputId": "8f682382-7742-4b42-82ae-3cda5f11572a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 1.64037002e+04,  1.59668100e+04,  1.49210661e+04,  1.49728312e+04,\n",
              "        1.60726675e+04,  1.59135982e+04, -1.81898940e-12,  5.06442970e+03,\n",
              "        1.46514848e+04,  1.66672433e+04])"
            ]
          },
          "execution_count": 120,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "inv_y[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cZsq0EQN_Lmn",
        "outputId": "ef922706-a8d2-46f9-815b-f74c7d7c2303"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([16547.10784058, 16421.53423296, 16142.58344181, 16021.37957052,\n",
              "       16176.92986801, 16287.35306359,  6842.38433945,  5001.91308594,\n",
              "       11691.75196453, 16058.50336633])"
            ]
          },
          "execution_count": 119,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "inv_yhat[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Gqet1M9HkW8",
        "outputId": "df1d967e-69bb-4de0-b356-f435dad26436"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([16547.10784058, 16421.53423296, 16142.58344181, 16021.37957052,\n",
              "       16176.92986801, 16287.35306359,  6842.38433945,  5001.91308594,\n",
              "       11691.75196453, 16058.50336633])"
            ]
          },
          "execution_count": 221,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "inv_yhat[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 632
        },
        "id": "3OWz-GbfWK3L",
        "outputId": "f3057504-3032-4026-b773-03acb217a3fa"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-ec656dd7-fd00-4c06-b61e-de304437f407\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ON_STREAM_HRS</th>\n",
              "      <th>AVG_DOWNHOLE_PRESSURE</th>\n",
              "      <th>AVG_DOWNHOLE_TEMPERATURE</th>\n",
              "      <th>AVG_CHOKE_SIZE_P</th>\n",
              "      <th>AVG_WHP_P</th>\n",
              "      <th>AVG_WHT_P</th>\n",
              "      <th>DP_CHOKE_SIZE</th>\n",
              "      <th>BORE_GAS_VOL</th>\n",
              "      <th>BORE_WAT_VOL</th>\n",
              "      <th>F_4_BORE_WI_VOL</th>\n",
              "      <th>F_5_BORE_WI_VOL</th>\n",
              "      <th>BORE_OIL_VOL</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DATEPRD</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2010-01-01</th>\n",
              "      <td>24.00000</td>\n",
              "      <td>3378.643673</td>\n",
              "      <td>223.079164</td>\n",
              "      <td>50.150825</td>\n",
              "      <td>749.568621</td>\n",
              "      <td>190.264943</td>\n",
              "      <td>271.390953</td>\n",
              "      <td>1.462166e+07</td>\n",
              "      <td>15304.241356</td>\n",
              "      <td>44109.287732</td>\n",
              "      <td>49054.221066</td>\n",
              "      <td>18593.749401</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-01-02</th>\n",
              "      <td>24.00000</td>\n",
              "      <td>3377.769461</td>\n",
              "      <td>223.095696</td>\n",
              "      <td>50.694654</td>\n",
              "      <td>744.664780</td>\n",
              "      <td>190.708397</td>\n",
              "      <td>266.368677</td>\n",
              "      <td>1.469266e+07</td>\n",
              "      <td>16519.118273</td>\n",
              "      <td>41936.969541</td>\n",
              "      <td>51515.296516</td>\n",
              "      <td>18701.242265</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-01-03</th>\n",
              "      <td>24.00000</td>\n",
              "      <td>3408.561097</td>\n",
              "      <td>223.074953</td>\n",
              "      <td>47.665676</td>\n",
              "      <td>774.827418</td>\n",
              "      <td>192.268341</td>\n",
              "      <td>299.398157</td>\n",
              "      <td>1.400904e+07</td>\n",
              "      <td>14796.150455</td>\n",
              "      <td>41114.572918</td>\n",
              "      <td>51717.286427</td>\n",
              "      <td>17799.912406</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-01-04</th>\n",
              "      <td>24.00000</td>\n",
              "      <td>3439.266918</td>\n",
              "      <td>223.022721</td>\n",
              "      <td>44.706230</td>\n",
              "      <td>806.160543</td>\n",
              "      <td>191.994925</td>\n",
              "      <td>333.246980</td>\n",
              "      <td>1.341015e+07</td>\n",
              "      <td>13428.619835</td>\n",
              "      <td>40267.292699</td>\n",
              "      <td>51948.640243</td>\n",
              "      <td>17002.616014</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-01-05</th>\n",
              "      <td>24.00000</td>\n",
              "      <td>3429.064568</td>\n",
              "      <td>223.035833</td>\n",
              "      <td>45.743761</td>\n",
              "      <td>792.735696</td>\n",
              "      <td>191.503603</td>\n",
              "      <td>318.470614</td>\n",
              "      <td>1.361768e+07</td>\n",
              "      <td>9839.905499</td>\n",
              "      <td>40524.238503</td>\n",
              "      <td>52129.744099</td>\n",
              "      <td>17270.939334</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-01-06</th>\n",
              "      <td>24.00000</td>\n",
              "      <td>3426.456339</td>\n",
              "      <td>223.052301</td>\n",
              "      <td>46.053981</td>\n",
              "      <td>787.778892</td>\n",
              "      <td>191.155238</td>\n",
              "      <td>313.483219</td>\n",
              "      <td>1.364834e+07</td>\n",
              "      <td>10054.073550</td>\n",
              "      <td>40733.215195</td>\n",
              "      <td>52212.108216</td>\n",
              "      <td>17331.761803</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-01-07</th>\n",
              "      <td>24.00000</td>\n",
              "      <td>3432.314222</td>\n",
              "      <td>223.052885</td>\n",
              "      <td>44.740102</td>\n",
              "      <td>791.388814</td>\n",
              "      <td>190.547894</td>\n",
              "      <td>317.780795</td>\n",
              "      <td>1.350971e+07</td>\n",
              "      <td>12837.943721</td>\n",
              "      <td>39969.857579</td>\n",
              "      <td>51109.971510</td>\n",
              "      <td>17138.601719</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-01-08</th>\n",
              "      <td>24.00000</td>\n",
              "      <td>3432.123127</td>\n",
              "      <td>223.061205</td>\n",
              "      <td>44.805229</td>\n",
              "      <td>788.842189</td>\n",
              "      <td>190.683690</td>\n",
              "      <td>315.702450</td>\n",
              "      <td>1.349732e+07</td>\n",
              "      <td>10488.510768</td>\n",
              "      <td>41079.035678</td>\n",
              "      <td>50933.111950</td>\n",
              "      <td>17127.657449</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-01-09</th>\n",
              "      <td>22.83333</td>\n",
              "      <td>3492.820009</td>\n",
              "      <td>222.998368</td>\n",
              "      <td>39.728795</td>\n",
              "      <td>841.210210</td>\n",
              "      <td>186.402569</td>\n",
              "      <td>369.184766</td>\n",
              "      <td>1.192758e+07</td>\n",
              "      <td>10120.619746</td>\n",
              "      <td>26561.870164</td>\n",
              "      <td>36311.076594</td>\n",
              "      <td>14477.823141</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-01-10</th>\n",
              "      <td>24.00000</td>\n",
              "      <td>3427.174100</td>\n",
              "      <td>223.045567</td>\n",
              "      <td>44.943710</td>\n",
              "      <td>784.502885</td>\n",
              "      <td>190.103419</td>\n",
              "      <td>311.207552</td>\n",
              "      <td>1.350295e+07</td>\n",
              "      <td>11071.387516</td>\n",
              "      <td>43049.644968</td>\n",
              "      <td>48695.944867</td>\n",
              "      <td>17149.483091</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ec656dd7-fd00-4c06-b61e-de304437f407')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ec656dd7-fd00-4c06-b61e-de304437f407 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ec656dd7-fd00-4c06-b61e-de304437f407');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "            ON_STREAM_HRS  AVG_DOWNHOLE_PRESSURE  AVG_DOWNHOLE_TEMPERATURE  \\\n",
              "DATEPRD                                                                      \n",
              "2010-01-01       24.00000            3378.643673                223.079164   \n",
              "2010-01-02       24.00000            3377.769461                223.095696   \n",
              "2010-01-03       24.00000            3408.561097                223.074953   \n",
              "2010-01-04       24.00000            3439.266918                223.022721   \n",
              "2010-01-05       24.00000            3429.064568                223.035833   \n",
              "2010-01-06       24.00000            3426.456339                223.052301   \n",
              "2010-01-07       24.00000            3432.314222                223.052885   \n",
              "2010-01-08       24.00000            3432.123127                223.061205   \n",
              "2010-01-09       22.83333            3492.820009                222.998368   \n",
              "2010-01-10       24.00000            3427.174100                223.045567   \n",
              "\n",
              "            AVG_CHOKE_SIZE_P   AVG_WHP_P   AVG_WHT_P  DP_CHOKE_SIZE  \\\n",
              "DATEPRD                                                               \n",
              "2010-01-01         50.150825  749.568621  190.264943     271.390953   \n",
              "2010-01-02         50.694654  744.664780  190.708397     266.368677   \n",
              "2010-01-03         47.665676  774.827418  192.268341     299.398157   \n",
              "2010-01-04         44.706230  806.160543  191.994925     333.246980   \n",
              "2010-01-05         45.743761  792.735696  191.503603     318.470614   \n",
              "2010-01-06         46.053981  787.778892  191.155238     313.483219   \n",
              "2010-01-07         44.740102  791.388814  190.547894     317.780795   \n",
              "2010-01-08         44.805229  788.842189  190.683690     315.702450   \n",
              "2010-01-09         39.728795  841.210210  186.402569     369.184766   \n",
              "2010-01-10         44.943710  784.502885  190.103419     311.207552   \n",
              "\n",
              "            BORE_GAS_VOL  BORE_WAT_VOL  F_4_BORE_WI_VOL  F_5_BORE_WI_VOL  \\\n",
              "DATEPRD                                                                    \n",
              "2010-01-01  1.462166e+07  15304.241356     44109.287732     49054.221066   \n",
              "2010-01-02  1.469266e+07  16519.118273     41936.969541     51515.296516   \n",
              "2010-01-03  1.400904e+07  14796.150455     41114.572918     51717.286427   \n",
              "2010-01-04  1.341015e+07  13428.619835     40267.292699     51948.640243   \n",
              "2010-01-05  1.361768e+07   9839.905499     40524.238503     52129.744099   \n",
              "2010-01-06  1.364834e+07  10054.073550     40733.215195     52212.108216   \n",
              "2010-01-07  1.350971e+07  12837.943721     39969.857579     51109.971510   \n",
              "2010-01-08  1.349732e+07  10488.510768     41079.035678     50933.111950   \n",
              "2010-01-09  1.192758e+07  10120.619746     26561.870164     36311.076594   \n",
              "2010-01-10  1.350295e+07  11071.387516     43049.644968     48695.944867   \n",
              "\n",
              "            BORE_OIL_VOL  \n",
              "DATEPRD                   \n",
              "2010-01-01  18593.749401  \n",
              "2010-01-02  18701.242265  \n",
              "2010-01-03  17799.912406  \n",
              "2010-01-04  17002.616014  \n",
              "2010-01-05  17270.939334  \n",
              "2010-01-06  17331.761803  \n",
              "2010-01-07  17138.601719  \n",
              "2010-01-08  17127.657449  \n",
              "2010-01-09  14477.823141  \n",
              "2010-01-10  17149.483091  "
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "series[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "id": "wtoOYzWMSlDL",
        "outputId": "0fca06fb-1341-4df2-bd1a-c41116db29ae"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-d49ee05f6653>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# pd.set_option('display.max_columns', None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mseries_supervised\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'test_y' is not defined"
          ]
        }
      ],
      "source": [
        "# pd.set_option('display.max_columns', None)\n",
        "series_supervised.iloc[-len(test_y):]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dO0Xcq-8ZF6Q"
      },
      "outputs": [],
      "source": [
        "# # time-dependent variables \n",
        "# shifted_ON_STREAM_HRS = series_diff[\"ON_STREAM_HRS\"].shift(-(timesteps + diff_order)).dropna()\n",
        "# shifted_ON_STREAM_HRS.index = series_supervised.index.values \n",
        "# shifted_AVG_CHOKE_SIZE_P = series_diff['AVG_CHOKE_SIZE_P'].shift(-(timesteps + diff_order)).dropna()\n",
        "# shifted_AVG_CHOKE_SIZE_P.index = series_supervised.index.values\n",
        "# series_supervised = pd.concat([shifted_ON_STREAM_HRS,shifted_AVG_CHOKE_SIZE_P, series_supervised], axis=1) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lH-2wA_ySOOX"
      },
      "outputs": [],
      "source": [
        "# #drop all the variables that we don't want to predict\n",
        "# vars_y = series_supervised.columns[-steps_ahead*len(series.columns):]\n",
        "# vars_name_to_drop = ['ON_STREAM_HRS(t+)']\n",
        "# vars_to_drop = vars_to_drop = [col for col in vars_y if col.startswith(vars_name_to_drop[0])]\n",
        "# series_supervised.drop(columns=vars_to_drop, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V_XXkH3W_Rac"
      },
      "outputs": [],
      "source": [
        "# # bring the ON_STREAM_HRS(t) variable forward one step and place it before the target variable\n",
        "# ON_STREAM_HRS_t = series_supervised.pop('ON_STREAM_HRS(t)')\n",
        "# series_supervised.insert(len(series_supervised.columns)-1, 'ON_STREAM_HRS(t)', ON_STREAM_HRS_t)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Mfg1jvYuTH5a"
      },
      "outputs": [],
      "source": [
        "merged_onStreams = series_supervised[\"ON_STREAM_HRS(t-1)\"] + (series_supervised[\"ON_STREAM_HRS(t)\"] ) #\n",
        "# bring the ON_STREAM_HRS(t) variable forward one step and place it before the target variable\n",
        "series_supervised.insert(len(series_supervised.columns)-3, 'merged_onStreams', merged_onStreams)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "mnwN9F7S42a7"
      },
      "outputs": [],
      "source": [
        "merged_choke = series_supervised[\"AVG_CHOKE_SIZE_P(t-1)\"] + (series_supervised[\"AVG_CHOKE_SIZE_P(t)\"] ) #\n",
        "# bring the ON_STREAM_HRS(t) variable forward one step and place it before the target variable\n",
        "series_supervised.insert(len(series_supervised.columns)-3, 'merged_choke', merged_choke)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "xBZ5zwBYLyFU"
      },
      "outputs": [],
      "source": [
        "merged_WI_F_4 = series_supervised[\"F_4_BORE_WI_VOL(t-1)\"] + (series_supervised[\"F_4_BORE_WI_VOL(t)\"] ) #\n",
        "# bring the ON_STREAM_HRS(t) variable forward one step and place it before the target variable\n",
        "series_supervised.insert(len(series_supervised.columns)-3, 'merged_WI_F_4', merged_WI_F_4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "xfAy8D4PLyyi"
      },
      "outputs": [],
      "source": [
        "merged_WI_F_5 = series_supervised[\"F_5_BORE_WI_VOL(t-1)\"] + (series_supervised[\"F_5_BORE_WI_VOL(t)\"] ) #\n",
        "# bring the ON_STREAM_HRS(t) variable forward one step and place it before the target variable\n",
        "series_supervised.insert(len(series_supervised.columns)-3, 'merged_WI_F_5', merged_WI_F_5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "LfWyvX8TI7WB"
      },
      "outputs": [],
      "source": [
        "series_supervised.drop(['ON_STREAM_HRS(t-1)', 'AVG_CHOKE_SIZE_P(t-1)',\"F_4_BORE_WI_VOL(t-1)\",\n",
        "                        \"F_5_BORE_WI_VOL(t-1)\"], axis=1, inplace= True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "3pKtD-x--GNV"
      },
      "outputs": [],
      "source": [
        "series_supervised.drop(['AVG_CHOKE_SIZE_P(t)','ON_STREAM_HRS(t)','AVG_DOWNHOLE_PRESSURE(t)', 'AVG_DOWNHOLE_TEMPERATURE(t)',\n",
        "                        'F_4_BORE_WI_VOL(t)','AVG_WHP_P(t)', 'AVG_WHT_P(t)', 'DP_CHOKE_SIZE(t)',\n",
        "                        'F_5_BORE_WI_VOL(t)', 'BORE_GAS_VOL(t)', 'BORE_WAT_VOL(t)'], axis=1, inplace= True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nmbQinIh7Gnp",
        "outputId": "fc7b17a0-c5c1-4f85-fa50-171af33074f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1466, 121) (367, 121)\n"
          ]
        }
      ],
      "source": [
        "# # split into train and test sets\n",
        "series_supervised = series_supervised.values\n",
        "train_size = int(series_supervised.shape[0] * 0.8)\n",
        "test_size = series_supervised.shape[0] - train_size\n",
        "train, test = series_supervised[0:train_size], series_supervised[train_size:]\n",
        "print(train.shape, test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tvaAPiiS7y4v",
        "outputId": "1e18c38f-2819-4d25-c670-50318d98eed3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1466, 121) (367, 121)\n"
          ]
        }
      ],
      "source": [
        "# transform the scale of the data\n",
        "scaler, train_scaled, test_scaled = scale(train, test)\n",
        "print(train_scaled.shape, test_scaled.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AjDT7Ud5l522",
        "outputId": "b2581afe-5917-46fa-8a78-a524e708d063"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1466, 10, 12) (1466, 1) (367, 10, 12) (367, 1)\n"
          ]
        }
      ],
      "source": [
        "# # reshape input to be 3D [samples, timesteps, features]\n",
        "n_features = len(series.columns) \n",
        "\n",
        "train_X, train_y = train_scaled[:, 0:-steps_ahead], train_scaled[:, -steps_ahead:]\n",
        "train_X = train_X.reshape(train_X.shape[0], timesteps, n_features)\n",
        "test_X, test_y = test_scaled[:, 0:-steps_ahead], test_scaled[:, -steps_ahead:]\n",
        "test_X = test_X.reshape(test_X.shape[0], timesteps, n_features )\n",
        "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import copy"
      ],
      "metadata": {
        "id": "1R3DH-kcMoi_"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "SeooCz3fWgh4",
        "outputId": "a235db4e-6810-4e6e-85bf-a073a645940c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1200\n",
            "733/733 - 4s - loss: 0.0167 - val_loss: 0.0048 - 4s/epoch - 6ms/step\n",
            "Epoch 2/1200\n",
            "733/733 - 2s - loss: 0.0103 - val_loss: 0.0043 - 2s/epoch - 3ms/step\n",
            "Epoch 3/1200\n",
            "733/733 - 2s - loss: 0.0082 - val_loss: 0.0038 - 2s/epoch - 3ms/step\n",
            "Epoch 4/1200\n",
            "733/733 - 2s - loss: 0.0070 - val_loss: 0.0033 - 2s/epoch - 3ms/step\n",
            "Epoch 5/1200\n",
            "733/733 - 3s - loss: 0.0062 - val_loss: 0.0028 - 3s/epoch - 3ms/step\n",
            "Epoch 6/1200\n",
            "733/733 - 2s - loss: 0.0057 - val_loss: 0.0024 - 2s/epoch - 3ms/step\n",
            "Epoch 7/1200\n",
            "733/733 - 2s - loss: 0.0053 - val_loss: 0.0021 - 2s/epoch - 3ms/step\n",
            "Epoch 8/1200\n",
            "733/733 - 2s - loss: 0.0049 - val_loss: 0.0018 - 2s/epoch - 3ms/step\n",
            "Epoch 9/1200\n",
            "733/733 - 3s - loss: 0.0047 - val_loss: 0.0016 - 3s/epoch - 3ms/step\n",
            "Epoch 10/1200\n",
            "733/733 - 2s - loss: 0.0045 - val_loss: 0.0014 - 2s/epoch - 3ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "best_model_10\n",
            "Epoch 11/1200\n",
            "733/733 - 2s - loss: 0.0043 - val_loss: 0.0013 - 2s/epoch - 3ms/step\n",
            "Epoch 12/1200\n",
            "733/733 - 2s - loss: 0.0041 - val_loss: 0.0012 - 2s/epoch - 3ms/step\n",
            "Epoch 13/1200\n",
            "733/733 - 3s - loss: 0.0039 - val_loss: 0.0011 - 3s/epoch - 3ms/step\n",
            "Epoch 14/1200\n",
            "733/733 - 3s - loss: 0.0038 - val_loss: 0.0011 - 3s/epoch - 3ms/step\n",
            "Epoch 15/1200\n",
            "733/733 - 2s - loss: 0.0036 - val_loss: 0.0011 - 2s/epoch - 3ms/step\n",
            "Epoch 16/1200\n",
            "733/733 - 3s - loss: 0.0035 - val_loss: 0.0011 - 3s/epoch - 3ms/step\n",
            "Epoch 17/1200\n",
            "733/733 - 2s - loss: 0.0034 - val_loss: 0.0011 - 2s/epoch - 3ms/step\n",
            "Epoch 18/1200\n",
            "733/733 - 2s - loss: 0.0033 - val_loss: 0.0011 - 2s/epoch - 3ms/step\n",
            "Epoch 19/1200\n",
            "733/733 - 2s - loss: 0.0032 - val_loss: 0.0011 - 2s/epoch - 3ms/step\n",
            "Epoch 20/1200\n",
            "733/733 - 3s - loss: 0.0031 - val_loss: 0.0011 - 3s/epoch - 3ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "best_model_17\n",
            "Epoch 21/1200\n",
            "733/733 - 2s - loss: 0.0030 - val_loss: 0.0011 - 2s/epoch - 3ms/step\n",
            "Epoch 22/1200\n",
            "733/733 - 2s - loss: 0.0029 - val_loss: 0.0011 - 2s/epoch - 3ms/step\n",
            "Epoch 23/1200\n",
            "733/733 - 2s - loss: 0.0028 - val_loss: 0.0011 - 2s/epoch - 3ms/step\n",
            "Epoch 24/1200\n",
            "733/733 - 2s - loss: 0.0027 - val_loss: 0.0012 - 2s/epoch - 3ms/step\n",
            "Epoch 25/1200\n",
            "733/733 - 2s - loss: 0.0027 - val_loss: 0.0012 - 2s/epoch - 3ms/step\n",
            "Epoch 26/1200\n",
            "733/733 - 2s - loss: 0.0026 - val_loss: 0.0012 - 2s/epoch - 3ms/step\n",
            "Epoch 27/1200\n",
            "733/733 - 3s - loss: 0.0025 - val_loss: 0.0012 - 3s/epoch - 4ms/step\n",
            "Epoch 28/1200\n",
            "733/733 - 2s - loss: 0.0025 - val_loss: 0.0013 - 2s/epoch - 3ms/step\n",
            "Epoch 29/1200\n",
            "733/733 - 2s - loss: 0.0024 - val_loss: 0.0013 - 2s/epoch - 3ms/step\n",
            "Epoch 30/1200\n",
            "733/733 - 2s - loss: 0.0024 - val_loss: 0.0013 - 2s/epoch - 3ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 31/1200\n",
            "733/733 - 2s - loss: 0.0024 - val_loss: 0.0013 - 2s/epoch - 3ms/step\n",
            "Epoch 32/1200\n",
            "733/733 - 2s - loss: 0.0023 - val_loss: 0.0014 - 2s/epoch - 3ms/step\n",
            "Epoch 33/1200\n",
            "733/733 - 2s - loss: 0.0023 - val_loss: 0.0014 - 2s/epoch - 3ms/step\n",
            "Epoch 34/1200\n",
            "733/733 - 2s - loss: 0.0023 - val_loss: 0.0014 - 2s/epoch - 3ms/step\n",
            "Epoch 35/1200\n",
            "733/733 - 2s - loss: 0.0022 - val_loss: 0.0014 - 2s/epoch - 3ms/step\n",
            "Epoch 36/1200\n",
            "733/733 - 3s - loss: 0.0022 - val_loss: 0.0015 - 3s/epoch - 3ms/step\n",
            "Epoch 37/1200\n",
            "733/733 - 2s - loss: 0.0022 - val_loss: 0.0015 - 2s/epoch - 3ms/step\n",
            "Epoch 38/1200\n",
            "733/733 - 2s - loss: 0.0021 - val_loss: 0.0015 - 2s/epoch - 3ms/step\n",
            "Epoch 39/1200\n",
            "733/733 - 2s - loss: 0.0021 - val_loss: 0.0015 - 2s/epoch - 3ms/step\n",
            "Epoch 40/1200\n",
            "733/733 - 2s - loss: 0.0021 - val_loss: 0.0015 - 2s/epoch - 3ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 41/1200\n",
            "733/733 - 2s - loss: 0.0021 - val_loss: 0.0016 - 2s/epoch - 3ms/step\n",
            "Epoch 42/1200\n",
            "733/733 - 2s - loss: 0.0021 - val_loss: 0.0016 - 2s/epoch - 3ms/step\n",
            "Epoch 43/1200\n",
            "733/733 - 2s - loss: 0.0020 - val_loss: 0.0016 - 2s/epoch - 3ms/step\n",
            "Epoch 44/1200\n",
            "733/733 - 2s - loss: 0.0020 - val_loss: 0.0016 - 2s/epoch - 3ms/step\n",
            "Epoch 45/1200\n",
            "733/733 - 2s - loss: 0.0020 - val_loss: 0.0016 - 2s/epoch - 3ms/step\n",
            "Epoch 46/1200\n",
            "733/733 - 2s - loss: 0.0020 - val_loss: 0.0016 - 2s/epoch - 3ms/step\n",
            "Epoch 47/1200\n",
            "733/733 - 2s - loss: 0.0020 - val_loss: 0.0017 - 2s/epoch - 3ms/step\n",
            "Epoch 48/1200\n",
            "733/733 - 2s - loss: 0.0019 - val_loss: 0.0017 - 2s/epoch - 3ms/step\n",
            "Epoch 49/1200\n",
            "733/733 - 2s - loss: 0.0019 - val_loss: 0.0017 - 2s/epoch - 3ms/step\n",
            "Epoch 50/1200\n",
            "733/733 - 2s - loss: 0.0019 - val_loss: 0.0017 - 2s/epoch - 3ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 51/1200\n",
            "733/733 - 2s - loss: 0.0019 - val_loss: 0.0017 - 2s/epoch - 3ms/step\n",
            "Epoch 52/1200\n",
            "733/733 - 2s - loss: 0.0019 - val_loss: 0.0017 - 2s/epoch - 3ms/step\n",
            "Epoch 53/1200\n",
            "733/733 - 2s - loss: 0.0019 - val_loss: 0.0017 - 2s/epoch - 3ms/step\n",
            "Epoch 54/1200\n",
            "733/733 - 2s - loss: 0.0019 - val_loss: 0.0017 - 2s/epoch - 3ms/step\n",
            "Epoch 55/1200\n",
            "733/733 - 2s - loss: 0.0018 - val_loss: 0.0017 - 2s/epoch - 3ms/step\n",
            "Epoch 56/1200\n",
            "733/733 - 2s - loss: 0.0018 - val_loss: 0.0017 - 2s/epoch - 3ms/step\n",
            "Epoch 57/1200\n",
            "733/733 - 2s - loss: 0.0018 - val_loss: 0.0017 - 2s/epoch - 3ms/step\n",
            "Epoch 58/1200\n",
            "733/733 - 2s - loss: 0.0018 - val_loss: 0.0018 - 2s/epoch - 3ms/step\n",
            "Epoch 59/1200\n",
            "733/733 - 2s - loss: 0.0018 - val_loss: 0.0018 - 2s/epoch - 3ms/step\n",
            "Epoch 60/1200\n",
            "733/733 - 2s - loss: 0.0018 - val_loss: 0.0018 - 2s/epoch - 3ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 61/1200\n",
            "733/733 - 2s - loss: 0.0018 - val_loss: 0.0018 - 2s/epoch - 3ms/step\n",
            "Epoch 62/1200\n",
            "733/733 - 2s - loss: 0.0018 - val_loss: 0.0018 - 2s/epoch - 3ms/step\n",
            "Epoch 63/1200\n",
            "733/733 - 2s - loss: 0.0017 - val_loss: 0.0018 - 2s/epoch - 3ms/step\n",
            "Epoch 64/1200\n",
            "733/733 - 2s - loss: 0.0017 - val_loss: 0.0018 - 2s/epoch - 3ms/step\n",
            "Epoch 65/1200\n",
            "733/733 - 3s - loss: 0.0017 - val_loss: 0.0018 - 3s/epoch - 3ms/step\n",
            "Epoch 66/1200\n",
            "733/733 - 3s - loss: 0.0017 - val_loss: 0.0018 - 3s/epoch - 3ms/step\n",
            "Epoch 67/1200\n",
            "733/733 - 2s - loss: 0.0017 - val_loss: 0.0018 - 2s/epoch - 3ms/step\n",
            "Epoch 68/1200\n",
            "733/733 - 2s - loss: 0.0017 - val_loss: 0.0018 - 2s/epoch - 3ms/step\n",
            "Epoch 69/1200\n",
            "733/733 - 2s - loss: 0.0017 - val_loss: 0.0018 - 2s/epoch - 3ms/step\n",
            "Epoch 70/1200\n",
            "733/733 - 3s - loss: 0.0017 - val_loss: 0.0018 - 3s/epoch - 3ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 71/1200\n",
            "733/733 - 2s - loss: 0.0017 - val_loss: 0.0018 - 2s/epoch - 3ms/step\n",
            "Epoch 72/1200\n",
            "733/733 - 2s - loss: 0.0017 - val_loss: 0.0018 - 2s/epoch - 3ms/step\n",
            "Epoch 73/1200\n",
            "733/733 - 2s - loss: 0.0016 - val_loss: 0.0018 - 2s/epoch - 3ms/step\n",
            "Epoch 74/1200\n",
            "733/733 - 2s - loss: 0.0016 - val_loss: 0.0018 - 2s/epoch - 3ms/step\n",
            "Epoch 75/1200\n",
            "733/733 - 2s - loss: 0.0016 - val_loss: 0.0018 - 2s/epoch - 3ms/step\n",
            "Epoch 76/1200\n",
            "733/733 - 2s - loss: 0.0016 - val_loss: 0.0018 - 2s/epoch - 3ms/step\n",
            "Epoch 77/1200\n",
            "733/733 - 2s - loss: 0.0016 - val_loss: 0.0018 - 2s/epoch - 3ms/step\n",
            "Epoch 78/1200\n",
            "733/733 - 2s - loss: 0.0016 - val_loss: 0.0018 - 2s/epoch - 3ms/step\n",
            "Epoch 79/1200\n",
            "733/733 - 2s - loss: 0.0016 - val_loss: 0.0018 - 2s/epoch - 3ms/step\n",
            "Epoch 80/1200\n",
            "733/733 - 2s - loss: 0.0016 - val_loss: 0.0018 - 2s/epoch - 3ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 81/1200\n",
            "733/733 - 2s - loss: 0.0016 - val_loss: 0.0017 - 2s/epoch - 3ms/step\n",
            "Epoch 82/1200\n",
            "733/733 - 2s - loss: 0.0016 - val_loss: 0.0017 - 2s/epoch - 3ms/step\n",
            "Epoch 83/1200\n",
            "733/733 - 2s - loss: 0.0016 - val_loss: 0.0017 - 2s/epoch - 3ms/step\n",
            "Epoch 84/1200\n",
            "733/733 - 2s - loss: 0.0015 - val_loss: 0.0017 - 2s/epoch - 3ms/step\n",
            "Epoch 85/1200\n",
            "733/733 - 2s - loss: 0.0015 - val_loss: 0.0017 - 2s/epoch - 3ms/step\n",
            "Epoch 86/1200\n",
            "733/733 - 2s - loss: 0.0015 - val_loss: 0.0017 - 2s/epoch - 3ms/step\n",
            "Epoch 87/1200\n",
            "733/733 - 3s - loss: 0.0015 - val_loss: 0.0017 - 3s/epoch - 4ms/step\n",
            "Epoch 88/1200\n",
            "733/733 - 2s - loss: 0.0015 - val_loss: 0.0017 - 2s/epoch - 3ms/step\n",
            "Epoch 89/1200\n",
            "733/733 - 3s - loss: 0.0015 - val_loss: 0.0017 - 3s/epoch - 3ms/step\n",
            "Epoch 90/1200\n",
            "733/733 - 3s - loss: 0.0015 - val_loss: 0.0017 - 3s/epoch - 3ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 91/1200\n",
            "733/733 - 2s - loss: 0.0015 - val_loss: 0.0017 - 2s/epoch - 3ms/step\n",
            "Epoch 92/1200\n",
            "733/733 - 2s - loss: 0.0015 - val_loss: 0.0016 - 2s/epoch - 3ms/step\n",
            "Epoch 93/1200\n",
            "733/733 - 2s - loss: 0.0015 - val_loss: 0.0016 - 2s/epoch - 3ms/step\n",
            "Epoch 94/1200\n",
            "733/733 - 2s - loss: 0.0015 - val_loss: 0.0016 - 2s/epoch - 3ms/step\n",
            "Epoch 95/1200\n",
            "733/733 - 2s - loss: 0.0015 - val_loss: 0.0016 - 2s/epoch - 3ms/step\n",
            "Epoch 96/1200\n",
            "733/733 - 2s - loss: 0.0015 - val_loss: 0.0016 - 2s/epoch - 3ms/step\n",
            "Epoch 97/1200\n",
            "733/733 - 2s - loss: 0.0015 - val_loss: 0.0016 - 2s/epoch - 3ms/step\n",
            "Epoch 98/1200\n",
            "733/733 - 2s - loss: 0.0015 - val_loss: 0.0016 - 2s/epoch - 3ms/step\n",
            "Epoch 99/1200\n",
            "733/733 - 2s - loss: 0.0014 - val_loss: 0.0016 - 2s/epoch - 3ms/step\n",
            "Epoch 100/1200\n",
            "733/733 - 2s - loss: 0.0014 - val_loss: 0.0016 - 2s/epoch - 3ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 101/1200\n",
            "733/733 - 2s - loss: 0.0014 - val_loss: 0.0016 - 2s/epoch - 3ms/step\n",
            "Epoch 102/1200\n",
            "733/733 - 2s - loss: 0.0014 - val_loss: 0.0015 - 2s/epoch - 3ms/step\n",
            "Epoch 103/1200\n",
            "733/733 - 2s - loss: 0.0014 - val_loss: 0.0015 - 2s/epoch - 3ms/step\n",
            "Epoch 104/1200\n",
            "733/733 - 2s - loss: 0.0014 - val_loss: 0.0015 - 2s/epoch - 3ms/step\n",
            "Epoch 105/1200\n",
            "733/733 - 2s - loss: 0.0014 - val_loss: 0.0015 - 2s/epoch - 3ms/step\n",
            "Epoch 106/1200\n",
            "733/733 - 2s - loss: 0.0014 - val_loss: 0.0015 - 2s/epoch - 3ms/step\n",
            "Epoch 107/1200\n",
            "733/733 - 2s - loss: 0.0014 - val_loss: 0.0015 - 2s/epoch - 3ms/step\n",
            "Epoch 108/1200\n",
            "733/733 - 2s - loss: 0.0014 - val_loss: 0.0015 - 2s/epoch - 3ms/step\n",
            "Epoch 109/1200\n",
            "733/733 - 2s - loss: 0.0014 - val_loss: 0.0015 - 2s/epoch - 3ms/step\n",
            "Epoch 110/1200\n",
            "733/733 - 2s - loss: 0.0014 - val_loss: 0.0015 - 2s/epoch - 3ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 111/1200\n",
            "733/733 - 2s - loss: 0.0014 - val_loss: 0.0014 - 2s/epoch - 3ms/step\n",
            "Epoch 112/1200\n",
            "733/733 - 2s - loss: 0.0014 - val_loss: 0.0014 - 2s/epoch - 3ms/step\n",
            "Epoch 113/1200\n",
            "733/733 - 2s - loss: 0.0014 - val_loss: 0.0014 - 2s/epoch - 3ms/step\n",
            "Epoch 114/1200\n",
            "733/733 - 2s - loss: 0.0014 - val_loss: 0.0014 - 2s/epoch - 3ms/step\n",
            "Epoch 115/1200\n",
            "733/733 - 2s - loss: 0.0014 - val_loss: 0.0014 - 2s/epoch - 3ms/step\n",
            "Epoch 116/1200\n",
            "733/733 - 2s - loss: 0.0014 - val_loss: 0.0014 - 2s/epoch - 3ms/step\n",
            "Epoch 117/1200\n",
            "733/733 - 2s - loss: 0.0014 - val_loss: 0.0014 - 2s/epoch - 3ms/step\n",
            "Epoch 118/1200\n",
            "733/733 - 2s - loss: 0.0014 - val_loss: 0.0014 - 2s/epoch - 3ms/step\n",
            "Epoch 119/1200\n",
            "733/733 - 2s - loss: 0.0013 - val_loss: 0.0014 - 2s/epoch - 3ms/step\n",
            "Epoch 120/1200\n",
            "733/733 - 2s - loss: 0.0013 - val_loss: 0.0014 - 2s/epoch - 3ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 121/1200\n",
            "733/733 - 2s - loss: 0.0013 - val_loss: 0.0014 - 2s/epoch - 3ms/step\n",
            "Epoch 122/1200\n",
            "733/733 - 2s - loss: 0.0013 - val_loss: 0.0014 - 2s/epoch - 3ms/step\n",
            "Epoch 123/1200\n",
            "733/733 - 2s - loss: 0.0013 - val_loss: 0.0014 - 2s/epoch - 3ms/step\n",
            "Epoch 124/1200\n",
            "733/733 - 2s - loss: 0.0013 - val_loss: 0.0013 - 2s/epoch - 3ms/step\n",
            "Epoch 125/1200\n",
            "733/733 - 3s - loss: 0.0013 - val_loss: 0.0013 - 3s/epoch - 3ms/step\n",
            "Epoch 126/1200\n",
            "733/733 - 2s - loss: 0.0013 - val_loss: 0.0013 - 2s/epoch - 3ms/step\n",
            "Epoch 127/1200\n",
            "733/733 - 2s - loss: 0.0013 - val_loss: 0.0013 - 2s/epoch - 3ms/step\n",
            "Epoch 128/1200\n",
            "733/733 - 2s - loss: 0.0013 - val_loss: 0.0013 - 2s/epoch - 3ms/step\n",
            "Epoch 129/1200\n",
            "733/733 - 2s - loss: 0.0013 - val_loss: 0.0013 - 2s/epoch - 3ms/step\n",
            "Epoch 130/1200\n",
            "733/733 - 2s - loss: 0.0013 - val_loss: 0.0013 - 2s/epoch - 3ms/step\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_op_helper\u001b[0;34m(self, op, compute_device)\u001b[0m\n\u001b[1;32m   3817\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3818\u001b[0;31m       \u001b[0mkernel_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_op_to_kernel_label_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3819\u001b[0m       op._set_attr(\"_kernel\",  # pylint: disable=protected-access\n",
            "\u001b[0;31mKeyError\u001b[0m: 'Const'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-a40a685ad638>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;31m# Save the model every 50 epochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0mmodel_saved\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m         \u001b[0;31m# Load the best weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mmodel_saved\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'.mdl_wts.hdf5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.8/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    151\u001b[0m             \u001b[0mcopier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__deepcopy__\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcopier\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m                 \u001b[0mreductor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdispatch_table\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m__deepcopy__\u001b[0;34m(self, memo)\u001b[0m\n\u001b[1;32m    336\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m       new = pickle_utils.deserialize_model_from_bytecode(\n\u001b[0;32m--> 338\u001b[0;31m           *pickle_utils.serialize_model_as_bytecode(self))\n\u001b[0m\u001b[1;32m    339\u001b[0m       \u001b[0mmemo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/saving/pickle_utils.py\u001b[0m in \u001b[0;36mserialize_model_as_bytecode\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m     62\u001b[0m   \"\"\"\n\u001b[1;32m     63\u001b[0m   \u001b[0mtemp_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"ram://{uuid.uuid4()}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m   \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mtarfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"w\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0marchive\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, filepath, overwrite, include_optimizer, save_format, signatures, options, save_traces)\u001b[0m\n\u001b[1;32m   2433\u001b[0m     \"\"\"\n\u001b[1;32m   2434\u001b[0m     \u001b[0;31m# pylint: enable=line-too-long\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2435\u001b[0;31m     save.save_model(self, filepath, overwrite, include_optimizer, save_format,\n\u001b[0m\u001b[1;32m   2436\u001b[0m                     signatures, options, save_traces)\n\u001b[1;32m   2437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/saving/save.py\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(model, filepath, overwrite, include_optimizer, save_format, signatures, options, save_traces)\u001b[0m\n\u001b[1;32m    151\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mgeneric_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSharedObjectSavingScope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       saved_model_save.save(model, filepath, overwrite, include_optimizer,\n\u001b[0m\u001b[1;32m    154\u001b[0m                             signatures, options, save_traces)\n\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/saving/saved_model/save.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(model, filepath, overwrite, include_optimizer, signatures, options, save_traces)\u001b[0m\n\u001b[1;32m     91\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeprecated_internal_learning_phase_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras_option_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_traces\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m       saved_nodes, node_paths = save_lib.save_and_return_nodes(\n\u001b[0m\u001b[1;32m     94\u001b[0m           model, filepath, signatures, options)\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/save.py\u001b[0m in \u001b[0;36msave_and_return_nodes\u001b[0;34m(obj, export_dir, signatures, options, experimental_skip_checkpoint)\u001b[0m\n\u001b[1;32m   1323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m   _, exported_graph, object_saver, asset_info, saved_nodes, node_paths = (\n\u001b[0;32m-> 1325\u001b[0;31m       _build_meta_graph(obj, signatures, options, meta_graph_def))\n\u001b[0m\u001b[1;32m   1326\u001b[0m   saved_model.saved_model_schema_version = (\n\u001b[1;32m   1327\u001b[0m       constants.SAVED_MODEL_SCHEMA_VERSION)\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/save.py\u001b[0m in \u001b[0;36m_build_meta_graph\u001b[0;34m(obj, signatures, options, meta_graph_def)\u001b[0m\n\u001b[1;32m   1489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1490\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0msave_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1491\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_build_meta_graph_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta_graph_def\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/save.py\u001b[0m in \u001b[0;36m_build_meta_graph_impl\u001b[0;34m(obj, signatures, options, meta_graph_def)\u001b[0m\n\u001b[1;32m   1431\u001b[0m   \u001b[0maugmented_graph_view\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_AugmentedGraphView\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1432\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0msignatures\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1433\u001b[0;31m     signatures = signature_serialization.find_function_to_export(\n\u001b[0m\u001b[1;32m   1434\u001b[0m         augmented_graph_view)\n\u001b[1;32m   1435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/signature_serialization.py\u001b[0m in \u001b[0;36mfind_function_to_export\u001b[0;34m(saveable_view)\u001b[0m\n\u001b[1;32m    101\u001b[0m   \u001b[0;31m# serving that model way later in the process stops working.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m   \u001b[0mpossible_signatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchild\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchildren\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdef_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConcreteFunction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/save.py\u001b[0m in \u001b[0;36mlist_children\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    141\u001b[0m       \u001b[0mchildren\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_children_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m       for name, child in super(_AugmentedGraphView, self).list_children(\n\u001b[0m\u001b[1;32m    144\u001b[0m           \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m           \u001b[0msave_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSaveType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSAVEDMODEL\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/tracking/graph_view.py\u001b[0m in \u001b[0;36mlist_children\u001b[0;34m(self, obj, save_type, **kwargs)\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_initialize_trackable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m     children = [base.TrackableReference(name, ref) for name, ref\n\u001b[0;32m--> 203\u001b[0;31m                 in obj._trackable_children(save_type, **kwargs).items()]\n\u001b[0m\u001b[1;32m    204\u001b[0m     \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/functional.py\u001b[0m in \u001b[0;36m_trackable_children\u001b[0;34m(self, save_type, **kwargs)\u001b[0m\n\u001b[1;32m    407\u001b[0m     \u001b[0mdependencies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_layer_checkpoint_dependencies\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m     dependencies.update(\n\u001b[0;32m--> 409\u001b[0;31m         super(Functional, self)._trackable_children(save_type, **kwargs))\n\u001b[0m\u001b[1;32m    410\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdependencies\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_trackable_children\u001b[0;34m(self, save_type, **kwargs)\u001b[0m\n\u001b[1;32m   3199\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_tf_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3201\u001b[0;31m     \u001b[0mchildren\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trackable_children\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3203\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msave_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'savedmodel'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_trackable_children\u001b[0;34m(self, save_type, **kwargs)\u001b[0m\n\u001b[1;32m   3172\u001b[0m       \u001b[0;31m# that any input shape changes are applied before getting the config of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3173\u001b[0m       \u001b[0;31m# the model.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3174\u001b[0;31m       \u001b[0mchildren\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trackable_saved_model_saver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrackable_children\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3175\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3176\u001b[0m       \u001b[0mchildren\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/saving/saved_model/base_serialization.py\u001b[0m in \u001b[0;36mtrackable_children\u001b[0;34m(self, serialization_cache)\u001b[0m\n\u001b[1;32m     57\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     \u001b[0mchildren\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjects_to_serialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mserialization_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m     \u001b[0mchildren\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctions_to_serialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mserialization_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mchildren\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/saving/saved_model/layer_serialization.py\u001b[0m in \u001b[0;36mobjects_to_serialize\u001b[0;34m(self, serialization_cache)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mobjects_to_serialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserialization_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m     return (self._get_serialized_attributes(\n\u001b[0m\u001b[1;32m     69\u001b[0m         serialization_cache).objects_to_serialize)\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/saving/saved_model/layer_serialization.py\u001b[0m in \u001b[0;36m_get_serialized_attributes\u001b[0;34m(self, serialization_cache)\u001b[0m\n\u001b[1;32m     86\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mserialized_attr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m     object_dict, function_dict = self._get_serialized_attributes_internal(\n\u001b[0m\u001b[1;32m     89\u001b[0m         serialization_cache)\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/saving/saved_model/model_serialization.py\u001b[0m in \u001b[0;36m_get_serialized_attributes_internal\u001b[0;34m(self, serialization_cache)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;31m# cache (i.e. this is the root level object).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mserialization_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mconstants\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKERAS_CACHE_KEY\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m       \u001b[0mdefault_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_impl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_save_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;31m# Other than the default signature function, all other attributes match with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/saving/saved_model/save_impl.py\u001b[0m in \u001b[0;36mdefault_save_signature\u001b[0;34m(layer)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdefault_save_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m   \u001b[0moriginal_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_reset_layer_losses\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m   \u001b[0mfn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msaving_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_model_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m   \u001b[0m_restore_layer_losses\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal_losses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/saving/saving_utils.py\u001b[0m in \u001b[0;36mtrace_model_call\u001b[0;34m(model, input_signature)\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapped_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_concrete_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mget_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget_concrete_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m     \u001b[0;31m# Implements GenericFunction.get_concrete_function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m     \u001b[0mconcrete\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_concrete_function_garbage_collected\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1240\u001b[0m     \u001b[0mconcrete\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_garbage_collector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mconcrete\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1217\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m         \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1220\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize_uninitialized_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    783\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    784\u001b[0m     self._concrete_stateful_fn = (\n\u001b[0;32m--> 785\u001b[0;31m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    786\u001b[0m             *args, **kwds))\n\u001b[1;32m    787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2478\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2479\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2480\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2481\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2482\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2709\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache_key\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_placeholder_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2710\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2711\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2712\u001b[0m           self._function_cache.add(cache_key, cache_key_deletion_observer,\n\u001b[1;32m   2713\u001b[0m                                    graph_function)\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2625\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2626\u001b[0m     graph_function = ConcreteFunction(\n\u001b[0;32m-> 2627\u001b[0;31m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m   2628\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2629\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1139\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1141\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    675\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 677\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    678\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1114\u001b[0m           \u001b[0;31m# TODO(mdan): Push this block higher in tf.function's call stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1115\u001b[0m           \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1116\u001b[0;31m             return autograph.converted_call(\n\u001b[0m\u001b[1;32m   1117\u001b[0m                 \u001b[0moriginal_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1118\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    437\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/saving/saving_utils.py\u001b[0m in \u001b[0;36mtf___wrapped_model\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     12\u001b[0m                 \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'training'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_layer_utils\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m                 \u001b[0moutput_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    329\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_in_allowlist_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Allowlisted %s: from cache'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_status_ctx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDISABLED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    488\u001b[0m       \u001b[0mlayout_map_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_subclass_model_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_layout_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 490\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    491\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mdoc_controls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdoc_in_current_and_subclasses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1012\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1013\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1014\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0mbound_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_keras_call_info_injected'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/sequential.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    372\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_graph_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 374\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m  \u001b[0;31m# handle the corner case where self.layers is empty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/functional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    456\u001b[0m         \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mtensors\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mthere\u001b[0m \u001b[0mare\u001b[0m \u001b[0mmore\u001b[0m \u001b[0mthan\u001b[0m \u001b[0mone\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m     \"\"\"\n\u001b[0;32m--> 458\u001b[0;31m     return self._run_internal_graph(\n\u001b[0m\u001b[1;32m    459\u001b[0m         inputs, training=training, mask=mask)\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/functional.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_arguments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    597\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m         \u001b[0;31m# Update tensor_dict.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/layers/rnn/base_rnn.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[1;32m    513\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconstants\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 515\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m     \u001b[0;31m# If any of `initial_state` or `constants` are specified and are Keras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1012\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1013\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1014\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0mbound_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_keras_call_info_injected'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/layers/rnn/lstm.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, mask, training, initial_state)\u001b[0m\n\u001b[1;32m    556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m     \u001b[0;31m# LSTM does not support constants. Ignore it during process.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 558\u001b[0;31m     \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    559\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/layers/rnn/base_rnn.py\u001b[0m in \u001b[0;36m_process_inputs\u001b[0;34m(self, inputs, initial_state, constants)\u001b[0m\n\u001b[1;32m    723\u001b[0m       )\n\u001b[1;32m    724\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 725\u001b[0;31m       \u001b[0minitial_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_initial_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    726\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_state\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/layers/rnn/base_rnn.py\u001b[0m in \u001b[0;36mget_initial_state\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m     \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m     \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime_major\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m     \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mget_initial_state_fn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mop_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1080\u001b[0m       \u001b[0;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36m_slice_helper\u001b[0;34m(tensor, slice_spec, var)\u001b[0m\n\u001b[1;32m   1071\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbegin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1072\u001b[0m       packed_begin, packed_end, packed_strides = (stack(begin), stack(end),\n\u001b[0;32m-> 1073\u001b[0;31m                                                   stack(strides))\n\u001b[0m\u001b[1;32m   1074\u001b[0m       \u001b[0;31m# TODO(mdan): Instead of implicitly casting, it's better to enforce the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1075\u001b[0m       \u001b[0;31m# same dtypes.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mop_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1080\u001b[0m       \u001b[0;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mstack\u001b[0;34m(values, axis, name)\u001b[0m\n\u001b[1;32m   1467\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1468\u001b[0m       \u001b[0;31m# If the input is a constant list, it can be converted to a constant op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1469\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1470\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1471\u001b[0m       \u001b[0;32mpass\u001b[0m  \u001b[0;31m# Input list contains non-constant tensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/profiler/trace.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtrace_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1639\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1640\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1641\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1642\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    341\u001b[0m                                          as_ref=False):\n\u001b[1;32m    342\u001b[0m   \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 343\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcalled\u001b[0m \u001b[0mon\u001b[0m \u001b[0ma\u001b[0m \u001b[0msymbolic\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m   \"\"\"\n\u001b[0;32m--> 267\u001b[0;31m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0m\u001b[1;32m    268\u001b[0m                         allow_broadcast=True)\n\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    287\u001b[0m   \u001b[0mdtype_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m   \u001b[0mattrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"value\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtensor_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"dtype\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdtype_value\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m   const_tensor = g._create_op_internal(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    290\u001b[0m       \"Const\", [], [dtype_value.type], attrs=attrs, name=name).outputs[0]\n\u001b[1;32m    291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m    692\u001b[0m       \u001b[0minp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m       \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 694\u001b[0;31m     return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    695\u001b[0m         \u001b[0mop_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m         compute_device)\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m   3761\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3762\u001b[0m           op_def=op_def)\n\u001b[0;32m-> 3763\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3764\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_op_helper\u001b[0;34m(self, op, compute_device)\u001b[0m\n\u001b[1;32m   3816\u001b[0m     \u001b[0;31m# Apply a kernel label if one has been specified for this op type.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3817\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3818\u001b[0;31m       \u001b[0mkernel_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_op_to_kernel_label_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3819\u001b[0m       op._set_attr(\"_kernel\",  # pylint: disable=protected-access\n\u001b[1;32m   3820\u001b[0m                    attr_value_pb2.AttrValue(s=compat.as_bytes(kernel_label)))\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"  \n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
        "os.environ['PYTHONHASHSEED'] = '0'\n",
        "np.random.seed(42)\n",
        "np.random.seed(12345)\n",
        "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
        "\n",
        "from keras import backend as K\n",
        "tf.random.set_seed(1234)\n",
        "\n",
        "sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
        "K.set_session(sess)\n",
        "\n",
        "# fit the model\n",
        "neurons= [12]#12 \n",
        "n_epochs=700#186\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(neurons[0], activation=\"tanh\", input_shape=(timesteps, n_features)))\n",
        "model.add(Dense(steps_ahead)) # output layer\n",
        "model.compile(loss='mean_squared_error', optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4))\n",
        "\n",
        "# # early stopping to return the best model\n",
        "early_stopping = EarlyStopping(monitor='loss', patience=10, verbose=2, restore_best_weights=True, mode='min')\n",
        "# save the best weights if training is interrupted\n",
        "mcp_save = ModelCheckpoint('.mdl_wts.hdf5', save_best_only=True, monitor='val_loss', mode='min') \n",
        "#reduce_lr_loss = ReduceLROnPlateau(monitor='loss', factor=0.1, patience=5, verbose=1, min_delta=1e-4, mode='min')\n",
        "\n",
        "# Set the initial validation loss to a large value\n",
        "best_val_loss = float('inf')\n",
        "\n",
        "# Set the initial and total number of epochs\n",
        "initial_epoch = 1\n",
        "n_epochs = 1200\n",
        "loss_tracking = list()\n",
        "\n",
        "# Run the training loop\n",
        "for epoch in range(initial_epoch , n_epochs+1):\n",
        "    print(f'Epoch {epoch}/{n_epochs}')\n",
        "    # Train the model for one epoch\n",
        "    history = model.fit(train_X, train_y, callbacks=[early_stopping, mcp_save],\n",
        "                    epochs=1, batch_size=2, validation_data=(test_X, test_y), verbose=2,\n",
        "                     shuffle=False)\n",
        "    # validation loss at each epoch\n",
        "    validation_loss= model.evaluate(test_X, test_y, verbose=0)\n",
        "    loss_tracking.append(validation_loss)\n",
        "\n",
        "    # Save the model every 50 epochs\n",
        "    if epoch % 10 == 0:\n",
        "        model_saved = copy.deepcopy(model)\n",
        "        # Load the best weights\n",
        "        model_saved.load_weights(f'.mdl_wts.hdf5')\n",
        "        # Get the validation loss for the best weights\n",
        "        val_loss = model_saved.evaluate(test_X, test_y, verbose = 0)\n",
        "          \n",
        "        best_epoch = loss_tracking.index(val_loss) + 1\n",
        "        # If the validation loss is the best so far, save the model\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            # Save the model  in HDF5 foramt with a filename that includes the epoch number\n",
        "            model_saved = model_saved.save(f'best_model_{best_epoch}.h5')\n",
        "            print(f'best_model_{best_epoch}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_weights(f'.mdl_wts.hdf5')"
      ],
      "metadata": {
        "id": "Tzvrv-10FRF4"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"  \n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
        "os.environ['PYTHONHASHSEED'] = '0'\n",
        "np.random.seed(42)\n",
        "np.random.seed(12345)\n",
        "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
        "\n",
        "from keras import backend as K\n",
        "tf.random.set_seed(1234)\n",
        "\n",
        "sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
        "K.set_session(sess)\n",
        "\n",
        "# fit the model\n",
        "neurons= [12]#12 \n",
        "n_epochs=700#186\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(neurons[0], activation=\"tanh\", input_shape=(timesteps, n_features)))\n",
        "model.add(Dense(steps_ahead)) # output layer\n",
        "model.compile(loss='mean_squared_error', optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4))\n",
        "\n",
        "# # early stopping to return the best model\n",
        "early_stopping = EarlyStopping(monitor='loss', patience=10, verbose=2, restore_best_weights=True, mode='min')\n",
        "# save the best weights if training is interrupted\n",
        "mcp_save = ModelCheckpoint('.mdl_wts.hdf5', save_best_only=True, monitor='val_loss', mode='min') \n",
        "#reduce_lr_loss = ReduceLROnPlateau(monitor='loss', factor=0.1, patience=5, verbose=1, min_delta=1e-4, mode='min')\n",
        "\n",
        "# Set the initial validation loss to a large value\n",
        "best_val_loss = float('inf')\n",
        "\n",
        "# # Set the initial and total number of epochs\n",
        "# initial_epoch = 1\n",
        "# n_epochs = 1200\n",
        "# loss_tracking = list()\n",
        "\n",
        "\n",
        "# Train the model for one epoch\n",
        "history = model.fit(train_X, train_y, callbacks=[early_stopping, mcp_save],\n",
        "                epochs=n_epochs, batch_size=2, validation_data=(test_X, test_y), verbose=2,\n",
        "                    shuffle=False)\n",
        "# validation loss at each epoch\n",
        "# validation_loss= model.evaluate(test_X, test_y, verbose=0)\n",
        "# loss_tracking.append(validation_loss)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "td0GX8vP-9PM",
        "outputId": "6b6a0f7f-7b01-41fa-bd8a-38636f9a6efc"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/700\n",
            "733/733 - 4s - loss: 0.0167 - val_loss: 0.0048 - 4s/epoch - 6ms/step\n",
            "Epoch 2/700\n",
            "733/733 - 2s - loss: 0.0103 - val_loss: 0.0043 - 2s/epoch - 3ms/step\n",
            "Epoch 3/700\n",
            "733/733 - 3s - loss: 0.0082 - val_loss: 0.0038 - 3s/epoch - 3ms/step\n",
            "Epoch 4/700\n",
            "733/733 - 2s - loss: 0.0070 - val_loss: 0.0033 - 2s/epoch - 3ms/step\n",
            "Epoch 5/700\n",
            "733/733 - 2s - loss: 0.0062 - val_loss: 0.0028 - 2s/epoch - 3ms/step\n",
            "Epoch 6/700\n",
            "733/733 - 2s - loss: 0.0057 - val_loss: 0.0024 - 2s/epoch - 3ms/step\n",
            "Epoch 7/700\n",
            "733/733 - 2s - loss: 0.0053 - val_loss: 0.0021 - 2s/epoch - 3ms/step\n",
            "Epoch 8/700\n",
            "733/733 - 2s - loss: 0.0049 - val_loss: 0.0018 - 2s/epoch - 3ms/step\n",
            "Epoch 9/700\n",
            "733/733 - 3s - loss: 0.0047 - val_loss: 0.0016 - 3s/epoch - 4ms/step\n",
            "Epoch 10/700\n",
            "733/733 - 3s - loss: 0.0045 - val_loss: 0.0014 - 3s/epoch - 3ms/step\n",
            "Epoch 11/700\n",
            "733/733 - 2s - loss: 0.0043 - val_loss: 0.0013 - 2s/epoch - 3ms/step\n",
            "Epoch 12/700\n",
            "733/733 - 2s - loss: 0.0041 - val_loss: 0.0012 - 2s/epoch - 3ms/step\n",
            "Epoch 13/700\n",
            "733/733 - 2s - loss: 0.0039 - val_loss: 0.0011 - 2s/epoch - 3ms/step\n",
            "Epoch 14/700\n",
            "733/733 - 2s - loss: 0.0038 - val_loss: 0.0011 - 2s/epoch - 3ms/step\n",
            "Epoch 15/700\n",
            "733/733 - 2s - loss: 0.0036 - val_loss: 0.0011 - 2s/epoch - 3ms/step\n",
            "Epoch 16/700\n",
            "733/733 - 2s - loss: 0.0035 - val_loss: 0.0011 - 2s/epoch - 3ms/step\n",
            "Epoch 17/700\n",
            "733/733 - 2s - loss: 0.0034 - val_loss: 0.0011 - 2s/epoch - 3ms/step\n",
            "Epoch 18/700\n",
            "733/733 - 2s - loss: 0.0033 - val_loss: 0.0011 - 2s/epoch - 3ms/step\n",
            "Epoch 19/700\n",
            "733/733 - 2s - loss: 0.0032 - val_loss: 0.0011 - 2s/epoch - 3ms/step\n",
            "Epoch 20/700\n",
            "733/733 - 2s - loss: 0.0031 - val_loss: 0.0011 - 2s/epoch - 3ms/step\n",
            "Epoch 21/700\n",
            "733/733 - 2s - loss: 0.0030 - val_loss: 0.0011 - 2s/epoch - 3ms/step\n",
            "Epoch 22/700\n",
            "733/733 - 2s - loss: 0.0029 - val_loss: 0.0011 - 2s/epoch - 3ms/step\n",
            "Epoch 23/700\n",
            "733/733 - 2s - loss: 0.0028 - val_loss: 0.0011 - 2s/epoch - 3ms/step\n",
            "Epoch 24/700\n",
            "733/733 - 2s - loss: 0.0027 - val_loss: 0.0012 - 2s/epoch - 3ms/step\n",
            "Epoch 25/700\n",
            "733/733 - 2s - loss: 0.0027 - val_loss: 0.0012 - 2s/epoch - 3ms/step\n",
            "Epoch 26/700\n",
            "733/733 - 2s - loss: 0.0026 - val_loss: 0.0012 - 2s/epoch - 3ms/step\n",
            "Epoch 27/700\n",
            "733/733 - 2s - loss: 0.0025 - val_loss: 0.0012 - 2s/epoch - 3ms/step\n",
            "Epoch 28/700\n",
            "733/733 - 2s - loss: 0.0025 - val_loss: 0.0013 - 2s/epoch - 3ms/step\n",
            "Epoch 29/700\n",
            "733/733 - 2s - loss: 0.0024 - val_loss: 0.0013 - 2s/epoch - 3ms/step\n",
            "Epoch 30/700\n",
            "733/733 - 2s - loss: 0.0024 - val_loss: 0.0013 - 2s/epoch - 3ms/step\n",
            "Epoch 31/700\n",
            "733/733 - 2s - loss: 0.0024 - val_loss: 0.0013 - 2s/epoch - 3ms/step\n",
            "Epoch 32/700\n",
            "733/733 - 2s - loss: 0.0023 - val_loss: 0.0014 - 2s/epoch - 3ms/step\n",
            "Epoch 33/700\n",
            "733/733 - 2s - loss: 0.0023 - val_loss: 0.0014 - 2s/epoch - 3ms/step\n",
            "Epoch 34/700\n",
            "733/733 - 2s - loss: 0.0023 - val_loss: 0.0014 - 2s/epoch - 3ms/step\n",
            "Epoch 35/700\n",
            "733/733 - 2s - loss: 0.0022 - val_loss: 0.0014 - 2s/epoch - 3ms/step\n",
            "Epoch 36/700\n",
            "733/733 - 2s - loss: 0.0022 - val_loss: 0.0015 - 2s/epoch - 3ms/step\n",
            "Epoch 37/700\n",
            "733/733 - 2s - loss: 0.0022 - val_loss: 0.0015 - 2s/epoch - 3ms/step\n",
            "Epoch 38/700\n",
            "733/733 - 2s - loss: 0.0021 - val_loss: 0.0015 - 2s/epoch - 3ms/step\n",
            "Epoch 39/700\n",
            "733/733 - 2s - loss: 0.0021 - val_loss: 0.0015 - 2s/epoch - 3ms/step\n",
            "Epoch 40/700\n",
            "733/733 - 2s - loss: 0.0021 - val_loss: 0.0015 - 2s/epoch - 3ms/step\n",
            "Epoch 41/700\n",
            "733/733 - 2s - loss: 0.0021 - val_loss: 0.0016 - 2s/epoch - 3ms/step\n",
            "Epoch 42/700\n",
            "733/733 - 2s - loss: 0.0021 - val_loss: 0.0016 - 2s/epoch - 3ms/step\n",
            "Epoch 43/700\n",
            "733/733 - 2s - loss: 0.0020 - val_loss: 0.0016 - 2s/epoch - 3ms/step\n",
            "Epoch 44/700\n",
            "733/733 - 2s - loss: 0.0020 - val_loss: 0.0016 - 2s/epoch - 3ms/step\n",
            "Epoch 45/700\n",
            "733/733 - 2s - loss: 0.0020 - val_loss: 0.0016 - 2s/epoch - 3ms/step\n",
            "Epoch 46/700\n",
            "733/733 - 2s - loss: 0.0020 - val_loss: 0.0016 - 2s/epoch - 3ms/step\n",
            "Epoch 47/700\n",
            "733/733 - 2s - loss: 0.0020 - val_loss: 0.0017 - 2s/epoch - 3ms/step\n",
            "Epoch 48/700\n",
            "733/733 - 2s - loss: 0.0019 - val_loss: 0.0017 - 2s/epoch - 3ms/step\n",
            "Epoch 49/700\n",
            "733/733 - 2s - loss: 0.0019 - val_loss: 0.0017 - 2s/epoch - 3ms/step\n",
            "Epoch 50/700\n",
            "733/733 - 2s - loss: 0.0019 - val_loss: 0.0017 - 2s/epoch - 3ms/step\n",
            "Epoch 51/700\n",
            "733/733 - 2s - loss: 0.0019 - val_loss: 0.0017 - 2s/epoch - 3ms/step\n",
            "Epoch 52/700\n",
            "733/733 - 2s - loss: 0.0019 - val_loss: 0.0017 - 2s/epoch - 3ms/step\n",
            "Epoch 53/700\n",
            "733/733 - 2s - loss: 0.0019 - val_loss: 0.0017 - 2s/epoch - 3ms/step\n",
            "Epoch 54/700\n",
            "733/733 - 2s - loss: 0.0019 - val_loss: 0.0017 - 2s/epoch - 3ms/step\n",
            "Epoch 55/700\n",
            "733/733 - 2s - loss: 0.0018 - val_loss: 0.0017 - 2s/epoch - 3ms/step\n",
            "Epoch 56/700\n",
            "733/733 - 2s - loss: 0.0018 - val_loss: 0.0017 - 2s/epoch - 3ms/step\n",
            "Epoch 57/700\n",
            "733/733 - 2s - loss: 0.0018 - val_loss: 0.0017 - 2s/epoch - 3ms/step\n",
            "Epoch 58/700\n",
            "733/733 - 2s - loss: 0.0018 - val_loss: 0.0018 - 2s/epoch - 3ms/step\n",
            "Epoch 59/700\n",
            "733/733 - 2s - loss: 0.0018 - val_loss: 0.0018 - 2s/epoch - 3ms/step\n",
            "Epoch 60/700\n",
            "733/733 - 2s - loss: 0.0018 - val_loss: 0.0018 - 2s/epoch - 3ms/step\n",
            "Epoch 61/700\n",
            "733/733 - 2s - loss: 0.0018 - val_loss: 0.0018 - 2s/epoch - 3ms/step\n",
            "Epoch 62/700\n",
            "733/733 - 2s - loss: 0.0018 - val_loss: 0.0018 - 2s/epoch - 3ms/step\n",
            "Epoch 63/700\n",
            "733/733 - 2s - loss: 0.0017 - val_loss: 0.0018 - 2s/epoch - 3ms/step\n",
            "Epoch 64/700\n",
            "733/733 - 2s - loss: 0.0017 - val_loss: 0.0018 - 2s/epoch - 3ms/step\n",
            "Epoch 65/700\n",
            "733/733 - 2s - loss: 0.0017 - val_loss: 0.0018 - 2s/epoch - 3ms/step\n",
            "Epoch 66/700\n",
            "733/733 - 2s - loss: 0.0017 - val_loss: 0.0018 - 2s/epoch - 3ms/step\n",
            "Epoch 67/700\n",
            "733/733 - 2s - loss: 0.0017 - val_loss: 0.0018 - 2s/epoch - 3ms/step\n",
            "Epoch 68/700\n",
            "733/733 - 2s - loss: 0.0017 - val_loss: 0.0018 - 2s/epoch - 3ms/step\n",
            "Epoch 69/700\n",
            "733/733 - 2s - loss: 0.0017 - val_loss: 0.0018 - 2s/epoch - 3ms/step\n",
            "Epoch 70/700\n",
            "733/733 - 2s - loss: 0.0017 - val_loss: 0.0018 - 2s/epoch - 3ms/step\n",
            "Epoch 71/700\n",
            "733/733 - 2s - loss: 0.0017 - val_loss: 0.0018 - 2s/epoch - 3ms/step\n",
            "Epoch 72/700\n",
            "733/733 - 2s - loss: 0.0017 - val_loss: 0.0018 - 2s/epoch - 3ms/step\n",
            "Epoch 73/700\n",
            "733/733 - 2s - loss: 0.0016 - val_loss: 0.0018 - 2s/epoch - 3ms/step\n",
            "Epoch 74/700\n",
            "733/733 - 2s - loss: 0.0016 - val_loss: 0.0018 - 2s/epoch - 3ms/step\n",
            "Epoch 75/700\n",
            "733/733 - 2s - loss: 0.0016 - val_loss: 0.0018 - 2s/epoch - 3ms/step\n",
            "Epoch 76/700\n",
            "733/733 - 2s - loss: 0.0016 - val_loss: 0.0018 - 2s/epoch - 3ms/step\n",
            "Epoch 77/700\n",
            "733/733 - 2s - loss: 0.0016 - val_loss: 0.0018 - 2s/epoch - 3ms/step\n",
            "Epoch 78/700\n",
            "733/733 - 2s - loss: 0.0016 - val_loss: 0.0018 - 2s/epoch - 3ms/step\n",
            "Epoch 79/700\n",
            "733/733 - 2s - loss: 0.0016 - val_loss: 0.0018 - 2s/epoch - 3ms/step\n",
            "Epoch 80/700\n",
            "733/733 - 2s - loss: 0.0016 - val_loss: 0.0018 - 2s/epoch - 3ms/step\n",
            "Epoch 81/700\n",
            "733/733 - 2s - loss: 0.0016 - val_loss: 0.0017 - 2s/epoch - 3ms/step\n",
            "Epoch 82/700\n",
            "733/733 - 2s - loss: 0.0016 - val_loss: 0.0017 - 2s/epoch - 3ms/step\n",
            "Epoch 83/700\n",
            "733/733 - 2s - loss: 0.0016 - val_loss: 0.0017 - 2s/epoch - 3ms/step\n",
            "Epoch 84/700\n",
            "733/733 - 2s - loss: 0.0015 - val_loss: 0.0017 - 2s/epoch - 3ms/step\n",
            "Epoch 85/700\n",
            "733/733 - 2s - loss: 0.0015 - val_loss: 0.0017 - 2s/epoch - 3ms/step\n",
            "Epoch 86/700\n",
            "733/733 - 2s - loss: 0.0015 - val_loss: 0.0017 - 2s/epoch - 3ms/step\n",
            "Epoch 87/700\n",
            "733/733 - 2s - loss: 0.0015 - val_loss: 0.0017 - 2s/epoch - 3ms/step\n",
            "Epoch 88/700\n",
            "733/733 - 3s - loss: 0.0015 - val_loss: 0.0017 - 3s/epoch - 3ms/step\n",
            "Epoch 89/700\n",
            "733/733 - 2s - loss: 0.0015 - val_loss: 0.0017 - 2s/epoch - 3ms/step\n",
            "Epoch 90/700\n",
            "733/733 - 2s - loss: 0.0015 - val_loss: 0.0017 - 2s/epoch - 3ms/step\n",
            "Epoch 91/700\n",
            "733/733 - 2s - loss: 0.0015 - val_loss: 0.0017 - 2s/epoch - 3ms/step\n",
            "Epoch 92/700\n",
            "733/733 - 2s - loss: 0.0015 - val_loss: 0.0016 - 2s/epoch - 3ms/step\n",
            "Epoch 93/700\n",
            "733/733 - 2s - loss: 0.0015 - val_loss: 0.0016 - 2s/epoch - 3ms/step\n",
            "Epoch 94/700\n",
            "733/733 - 2s - loss: 0.0015 - val_loss: 0.0016 - 2s/epoch - 3ms/step\n",
            "Epoch 95/700\n",
            "733/733 - 2s - loss: 0.0015 - val_loss: 0.0016 - 2s/epoch - 3ms/step\n",
            "Epoch 96/700\n",
            "733/733 - 2s - loss: 0.0015 - val_loss: 0.0016 - 2s/epoch - 3ms/step\n",
            "Epoch 97/700\n",
            "733/733 - 3s - loss: 0.0015 - val_loss: 0.0016 - 3s/epoch - 4ms/step\n",
            "Epoch 98/700\n",
            "733/733 - 3s - loss: 0.0015 - val_loss: 0.0016 - 3s/epoch - 4ms/step\n",
            "Epoch 99/700\n",
            "733/733 - 2s - loss: 0.0014 - val_loss: 0.0016 - 2s/epoch - 3ms/step\n",
            "Epoch 100/700\n",
            "733/733 - 2s - loss: 0.0014 - val_loss: 0.0016 - 2s/epoch - 3ms/step\n",
            "Epoch 101/700\n",
            "733/733 - 2s - loss: 0.0014 - val_loss: 0.0016 - 2s/epoch - 3ms/step\n",
            "Epoch 102/700\n",
            "733/733 - 2s - loss: 0.0014 - val_loss: 0.0015 - 2s/epoch - 3ms/step\n",
            "Epoch 103/700\n",
            "733/733 - 2s - loss: 0.0014 - val_loss: 0.0015 - 2s/epoch - 3ms/step\n",
            "Epoch 104/700\n",
            "733/733 - 2s - loss: 0.0014 - val_loss: 0.0015 - 2s/epoch - 3ms/step\n",
            "Epoch 105/700\n",
            "733/733 - 2s - loss: 0.0014 - val_loss: 0.0015 - 2s/epoch - 3ms/step\n",
            "Epoch 106/700\n",
            "733/733 - 2s - loss: 0.0014 - val_loss: 0.0015 - 2s/epoch - 3ms/step\n",
            "Epoch 107/700\n",
            "733/733 - 2s - loss: 0.0014 - val_loss: 0.0015 - 2s/epoch - 3ms/step\n",
            "Epoch 108/700\n",
            "733/733 - 2s - loss: 0.0014 - val_loss: 0.0015 - 2s/epoch - 3ms/step\n",
            "Epoch 109/700\n",
            "733/733 - 2s - loss: 0.0014 - val_loss: 0.0015 - 2s/epoch - 3ms/step\n",
            "Epoch 110/700\n",
            "733/733 - 2s - loss: 0.0014 - val_loss: 0.0015 - 2s/epoch - 3ms/step\n",
            "Epoch 111/700\n",
            "733/733 - 2s - loss: 0.0014 - val_loss: 0.0014 - 2s/epoch - 3ms/step\n",
            "Epoch 112/700\n",
            "733/733 - 2s - loss: 0.0014 - val_loss: 0.0014 - 2s/epoch - 3ms/step\n",
            "Epoch 113/700\n",
            "733/733 - 2s - loss: 0.0014 - val_loss: 0.0014 - 2s/epoch - 3ms/step\n",
            "Epoch 114/700\n",
            "733/733 - 2s - loss: 0.0014 - val_loss: 0.0014 - 2s/epoch - 3ms/step\n",
            "Epoch 115/700\n",
            "733/733 - 2s - loss: 0.0014 - val_loss: 0.0014 - 2s/epoch - 3ms/step\n",
            "Epoch 116/700\n",
            "733/733 - 2s - loss: 0.0014 - val_loss: 0.0014 - 2s/epoch - 3ms/step\n",
            "Epoch 117/700\n",
            "733/733 - 2s - loss: 0.0014 - val_loss: 0.0014 - 2s/epoch - 3ms/step\n",
            "Epoch 118/700\n",
            "733/733 - 2s - loss: 0.0014 - val_loss: 0.0014 - 2s/epoch - 3ms/step\n",
            "Epoch 119/700\n",
            "733/733 - 3s - loss: 0.0013 - val_loss: 0.0014 - 3s/epoch - 3ms/step\n",
            "Epoch 120/700\n",
            "733/733 - 3s - loss: 0.0013 - val_loss: 0.0014 - 3s/epoch - 3ms/step\n",
            "Epoch 121/700\n",
            "733/733 - 2s - loss: 0.0013 - val_loss: 0.0014 - 2s/epoch - 3ms/step\n",
            "Epoch 122/700\n",
            "733/733 - 2s - loss: 0.0013 - val_loss: 0.0014 - 2s/epoch - 3ms/step\n",
            "Epoch 123/700\n",
            "733/733 - 2s - loss: 0.0013 - val_loss: 0.0014 - 2s/epoch - 3ms/step\n",
            "Epoch 124/700\n",
            "733/733 - 2s - loss: 0.0013 - val_loss: 0.0013 - 2s/epoch - 3ms/step\n",
            "Epoch 125/700\n",
            "733/733 - 2s - loss: 0.0013 - val_loss: 0.0013 - 2s/epoch - 3ms/step\n",
            "Epoch 126/700\n",
            "733/733 - 2s - loss: 0.0013 - val_loss: 0.0013 - 2s/epoch - 3ms/step\n",
            "Epoch 127/700\n",
            "733/733 - 2s - loss: 0.0013 - val_loss: 0.0013 - 2s/epoch - 3ms/step\n",
            "Epoch 128/700\n",
            "733/733 - 2s - loss: 0.0013 - val_loss: 0.0013 - 2s/epoch - 3ms/step\n",
            "Epoch 129/700\n",
            "733/733 - 2s - loss: 0.0013 - val_loss: 0.0013 - 2s/epoch - 3ms/step\n",
            "Epoch 130/700\n",
            "733/733 - 2s - loss: 0.0013 - val_loss: 0.0013 - 2s/epoch - 3ms/step\n",
            "Epoch 131/700\n",
            "733/733 - 2s - loss: 0.0013 - val_loss: 0.0013 - 2s/epoch - 3ms/step\n",
            "Epoch 132/700\n",
            "733/733 - 2s - loss: 0.0013 - val_loss: 0.0013 - 2s/epoch - 3ms/step\n",
            "Epoch 133/700\n",
            "733/733 - 2s - loss: 0.0013 - val_loss: 0.0013 - 2s/epoch - 3ms/step\n",
            "Epoch 134/700\n",
            "733/733 - 2s - loss: 0.0013 - val_loss: 0.0013 - 2s/epoch - 3ms/step\n",
            "Epoch 135/700\n",
            "733/733 - 2s - loss: 0.0013 - val_loss: 0.0013 - 2s/epoch - 3ms/step\n",
            "Epoch 136/700\n",
            "733/733 - 2s - loss: 0.0013 - val_loss: 0.0013 - 2s/epoch - 3ms/step\n",
            "Epoch 137/700\n",
            "733/733 - 2s - loss: 0.0013 - val_loss: 0.0013 - 2s/epoch - 3ms/step\n",
            "Epoch 138/700\n",
            "733/733 - 2s - loss: 0.0013 - val_loss: 0.0013 - 2s/epoch - 3ms/step\n",
            "Epoch 139/700\n",
            "733/733 - 2s - loss: 0.0013 - val_loss: 0.0013 - 2s/epoch - 3ms/step\n",
            "Epoch 140/700\n",
            "733/733 - 2s - loss: 0.0013 - val_loss: 0.0012 - 2s/epoch - 3ms/step\n",
            "Epoch 141/700\n",
            "733/733 - 2s - loss: 0.0013 - val_loss: 0.0012 - 2s/epoch - 3ms/step\n",
            "Epoch 142/700\n",
            "733/733 - 2s - loss: 0.0013 - val_loss: 0.0012 - 2s/epoch - 3ms/step\n",
            "Epoch 143/700\n",
            "733/733 - 2s - loss: 0.0013 - val_loss: 0.0012 - 2s/epoch - 3ms/step\n",
            "Epoch 144/700\n",
            "733/733 - 2s - loss: 0.0012 - val_loss: 0.0012 - 2s/epoch - 3ms/step\n",
            "Epoch 145/700\n",
            "733/733 - 2s - loss: 0.0012 - val_loss: 0.0012 - 2s/epoch - 3ms/step\n",
            "Epoch 146/700\n",
            "733/733 - 2s - loss: 0.0012 - val_loss: 0.0012 - 2s/epoch - 3ms/step\n",
            "Epoch 147/700\n",
            "733/733 - 2s - loss: 0.0012 - val_loss: 0.0012 - 2s/epoch - 3ms/step\n",
            "Epoch 148/700\n",
            "733/733 - 2s - loss: 0.0012 - val_loss: 0.0012 - 2s/epoch - 3ms/step\n",
            "Epoch 149/700\n",
            "733/733 - 2s - loss: 0.0012 - val_loss: 0.0012 - 2s/epoch - 3ms/step\n",
            "Epoch 150/700\n",
            "733/733 - 2s - loss: 0.0012 - val_loss: 0.0012 - 2s/epoch - 3ms/step\n",
            "Epoch 151/700\n",
            "733/733 - 2s - loss: 0.0012 - val_loss: 0.0012 - 2s/epoch - 3ms/step\n",
            "Epoch 152/700\n",
            "733/733 - 2s - loss: 0.0012 - val_loss: 0.0012 - 2s/epoch - 3ms/step\n",
            "Epoch 153/700\n",
            "733/733 - 2s - loss: 0.0012 - val_loss: 0.0012 - 2s/epoch - 3ms/step\n",
            "Epoch 154/700\n",
            "733/733 - 2s - loss: 0.0012 - val_loss: 0.0012 - 2s/epoch - 3ms/step\n",
            "Epoch 155/700\n",
            "733/733 - 2s - loss: 0.0012 - val_loss: 0.0012 - 2s/epoch - 3ms/step\n",
            "Epoch 156/700\n",
            "733/733 - 2s - loss: 0.0012 - val_loss: 0.0012 - 2s/epoch - 3ms/step\n",
            "Epoch 157/700\n",
            "733/733 - 2s - loss: 0.0012 - val_loss: 0.0012 - 2s/epoch - 3ms/step\n",
            "Epoch 158/700\n",
            "733/733 - 2s - loss: 0.0012 - val_loss: 0.0012 - 2s/epoch - 3ms/step\n",
            "Epoch 159/700\n",
            "733/733 - 2s - loss: 0.0012 - val_loss: 0.0012 - 2s/epoch - 3ms/step\n",
            "Epoch 160/700\n",
            "733/733 - 2s - loss: 0.0012 - val_loss: 0.0012 - 2s/epoch - 3ms/step\n",
            "Epoch 161/700\n",
            "733/733 - 2s - loss: 0.0012 - val_loss: 0.0011 - 2s/epoch - 3ms/step\n",
            "Epoch 162/700\n",
            "733/733 - 2s - loss: 0.0012 - val_loss: 0.0011 - 2s/epoch - 3ms/step\n",
            "Epoch 163/700\n",
            "733/733 - 2s - loss: 0.0012 - val_loss: 0.0011 - 2s/epoch - 3ms/step\n",
            "Epoch 164/700\n",
            "733/733 - 2s - loss: 0.0012 - val_loss: 0.0011 - 2s/epoch - 3ms/step\n",
            "Epoch 165/700\n",
            "733/733 - 2s - loss: 0.0012 - val_loss: 0.0011 - 2s/epoch - 3ms/step\n",
            "Epoch 166/700\n",
            "733/733 - 2s - loss: 0.0012 - val_loss: 0.0011 - 2s/epoch - 3ms/step\n",
            "Epoch 167/700\n",
            "733/733 - 2s - loss: 0.0012 - val_loss: 0.0011 - 2s/epoch - 3ms/step\n",
            "Epoch 168/700\n",
            "733/733 - 2s - loss: 0.0012 - val_loss: 0.0011 - 2s/epoch - 3ms/step\n",
            "Epoch 169/700\n",
            "733/733 - 2s - loss: 0.0012 - val_loss: 0.0011 - 2s/epoch - 3ms/step\n",
            "Epoch 170/700\n",
            "733/733 - 2s - loss: 0.0012 - val_loss: 0.0011 - 2s/epoch - 3ms/step\n",
            "Epoch 171/700\n",
            "733/733 - 2s - loss: 0.0011 - val_loss: 0.0011 - 2s/epoch - 3ms/step\n",
            "Epoch 172/700\n",
            "733/733 - 2s - loss: 0.0011 - val_loss: 0.0011 - 2s/epoch - 3ms/step\n",
            "Epoch 173/700\n",
            "733/733 - 2s - loss: 0.0011 - val_loss: 0.0011 - 2s/epoch - 3ms/step\n",
            "Epoch 174/700\n",
            "733/733 - 2s - loss: 0.0011 - val_loss: 0.0011 - 2s/epoch - 3ms/step\n",
            "Epoch 175/700\n",
            "733/733 - 2s - loss: 0.0011 - val_loss: 0.0011 - 2s/epoch - 3ms/step\n",
            "Epoch 176/700\n",
            "733/733 - 2s - loss: 0.0011 - val_loss: 0.0011 - 2s/epoch - 3ms/step\n",
            "Epoch 177/700\n",
            "733/733 - 2s - loss: 0.0011 - val_loss: 0.0011 - 2s/epoch - 3ms/step\n",
            "Epoch 178/700\n",
            "733/733 - 2s - loss: 0.0011 - val_loss: 0.0011 - 2s/epoch - 3ms/step\n",
            "Epoch 179/700\n",
            "733/733 - 2s - loss: 0.0011 - val_loss: 0.0011 - 2s/epoch - 3ms/step\n",
            "Epoch 180/700\n",
            "733/733 - 2s - loss: 0.0011 - val_loss: 0.0011 - 2s/epoch - 3ms/step\n",
            "Epoch 181/700\n",
            "733/733 - 2s - loss: 0.0011 - val_loss: 0.0011 - 2s/epoch - 3ms/step\n",
            "Epoch 182/700\n",
            "733/733 - 2s - loss: 0.0011 - val_loss: 0.0011 - 2s/epoch - 3ms/step\n",
            "Epoch 183/700\n",
            "733/733 - 2s - loss: 0.0011 - val_loss: 0.0011 - 2s/epoch - 3ms/step\n",
            "Epoch 184/700\n",
            "733/733 - 2s - loss: 0.0011 - val_loss: 0.0010 - 2s/epoch - 3ms/step\n",
            "Epoch 185/700\n",
            "733/733 - 2s - loss: 0.0011 - val_loss: 0.0010 - 2s/epoch - 3ms/step\n",
            "Epoch 186/700\n",
            "733/733 - 2s - loss: 0.0011 - val_loss: 0.0010 - 2s/epoch - 3ms/step\n",
            "Epoch 187/700\n",
            "733/733 - 2s - loss: 0.0011 - val_loss: 0.0010 - 2s/epoch - 3ms/step\n",
            "Epoch 188/700\n",
            "733/733 - 2s - loss: 0.0011 - val_loss: 0.0010 - 2s/epoch - 3ms/step\n",
            "Epoch 189/700\n",
            "733/733 - 2s - loss: 0.0011 - val_loss: 0.0010 - 2s/epoch - 3ms/step\n",
            "Epoch 190/700\n",
            "733/733 - 2s - loss: 0.0011 - val_loss: 0.0010 - 2s/epoch - 3ms/step\n",
            "Epoch 191/700\n",
            "733/733 - 2s - loss: 0.0011 - val_loss: 0.0010 - 2s/epoch - 3ms/step\n",
            "Epoch 192/700\n",
            "733/733 - 2s - loss: 0.0011 - val_loss: 0.0010 - 2s/epoch - 3ms/step\n",
            "Epoch 193/700\n",
            "733/733 - 2s - loss: 0.0011 - val_loss: 0.0010 - 2s/epoch - 3ms/step\n",
            "Epoch 194/700\n",
            "733/733 - 2s - loss: 0.0011 - val_loss: 0.0010 - 2s/epoch - 3ms/step\n",
            "Epoch 195/700\n",
            "733/733 - 2s - loss: 0.0011 - val_loss: 0.0010 - 2s/epoch - 3ms/step\n",
            "Epoch 196/700\n",
            "733/733 - 2s - loss: 0.0011 - val_loss: 9.9660e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 197/700\n",
            "733/733 - 2s - loss: 0.0011 - val_loss: 9.9246e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 198/700\n",
            "733/733 - 2s - loss: 0.0011 - val_loss: 9.8833e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 199/700\n",
            "733/733 - 2s - loss: 0.0011 - val_loss: 9.8420e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 200/700\n",
            "733/733 - 2s - loss: 0.0010 - val_loss: 9.8008e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 201/700\n",
            "733/733 - 2s - loss: 0.0010 - val_loss: 9.7595e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 202/700\n",
            "733/733 - 2s - loss: 0.0010 - val_loss: 9.7184e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 203/700\n",
            "733/733 - 2s - loss: 0.0010 - val_loss: 9.6773e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 204/700\n",
            "733/733 - 2s - loss: 0.0010 - val_loss: 9.6362e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 205/700\n",
            "733/733 - 2s - loss: 0.0010 - val_loss: 9.5952e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 206/700\n",
            "733/733 - 3s - loss: 0.0010 - val_loss: 9.5541e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 207/700\n",
            "733/733 - 2s - loss: 0.0010 - val_loss: 9.5131e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 208/700\n",
            "733/733 - 2s - loss: 0.0010 - val_loss: 9.4722e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 209/700\n",
            "733/733 - 2s - loss: 0.0010 - val_loss: 9.4312e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 210/700\n",
            "733/733 - 2s - loss: 0.0010 - val_loss: 9.3903e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 211/700\n",
            "733/733 - 2s - loss: 0.0010 - val_loss: 9.3493e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 212/700\n",
            "733/733 - 2s - loss: 0.0010 - val_loss: 9.3084e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 213/700\n",
            "733/733 - 2s - loss: 0.0010 - val_loss: 9.2674e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 214/700\n",
            "733/733 - 2s - loss: 0.0010 - val_loss: 9.2265e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 215/700\n",
            "733/733 - 2s - loss: 9.9916e-04 - val_loss: 9.1856e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 216/700\n",
            "733/733 - 2s - loss: 9.9592e-04 - val_loss: 9.1446e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 217/700\n",
            "733/733 - 2s - loss: 9.9269e-04 - val_loss: 9.1037e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 218/700\n",
            "733/733 - 2s - loss: 9.8948e-04 - val_loss: 9.0628e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 219/700\n",
            "733/733 - 2s - loss: 9.8628e-04 - val_loss: 9.0219e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 220/700\n",
            "733/733 - 2s - loss: 9.8310e-04 - val_loss: 8.9810e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 221/700\n",
            "733/733 - 2s - loss: 9.7993e-04 - val_loss: 8.9401e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 222/700\n",
            "733/733 - 2s - loss: 9.7677e-04 - val_loss: 8.8993e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 223/700\n",
            "733/733 - 2s - loss: 9.7363e-04 - val_loss: 8.8585e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 224/700\n",
            "733/733 - 2s - loss: 9.7051e-04 - val_loss: 8.8176e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 225/700\n",
            "733/733 - 2s - loss: 9.6740e-04 - val_loss: 8.7768e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 226/700\n",
            "733/733 - 2s - loss: 9.6431e-04 - val_loss: 8.7360e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 227/700\n",
            "733/733 - 2s - loss: 9.6123e-04 - val_loss: 8.6953e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 228/700\n",
            "733/733 - 3s - loss: 9.5817e-04 - val_loss: 8.6546e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 229/700\n",
            "733/733 - 2s - loss: 9.5513e-04 - val_loss: 8.6140e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 230/700\n",
            "733/733 - 2s - loss: 9.5210e-04 - val_loss: 8.5733e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 231/700\n",
            "733/733 - 2s - loss: 9.4909e-04 - val_loss: 8.5327e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 232/700\n",
            "733/733 - 2s - loss: 9.4610e-04 - val_loss: 8.4922e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 233/700\n",
            "733/733 - 2s - loss: 9.4312e-04 - val_loss: 8.4518e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 234/700\n",
            "733/733 - 2s - loss: 9.4017e-04 - val_loss: 8.4114e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 235/700\n",
            "733/733 - 2s - loss: 9.3723e-04 - val_loss: 8.3710e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 236/700\n",
            "733/733 - 2s - loss: 9.3430e-04 - val_loss: 8.3308e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 237/700\n",
            "733/733 - 2s - loss: 9.3140e-04 - val_loss: 8.2907e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 238/700\n",
            "733/733 - 2s - loss: 9.2851e-04 - val_loss: 8.2506e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 239/700\n",
            "733/733 - 2s - loss: 9.2565e-04 - val_loss: 8.2107e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 240/700\n",
            "733/733 - 2s - loss: 9.2280e-04 - val_loss: 8.1708e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 241/700\n",
            "733/733 - 2s - loss: 9.1997e-04 - val_loss: 8.1311e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 242/700\n",
            "733/733 - 2s - loss: 9.1715e-04 - val_loss: 8.0915e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 243/700\n",
            "733/733 - 2s - loss: 9.1436e-04 - val_loss: 8.0520e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 244/700\n",
            "733/733 - 2s - loss: 9.1158e-04 - val_loss: 8.0126e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 245/700\n",
            "733/733 - 2s - loss: 9.0883e-04 - val_loss: 7.9734e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 246/700\n",
            "733/733 - 2s - loss: 9.0609e-04 - val_loss: 7.9343e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 247/700\n",
            "733/733 - 2s - loss: 9.0337e-04 - val_loss: 7.8955e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 248/700\n",
            "733/733 - 2s - loss: 9.0067e-04 - val_loss: 7.8567e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 249/700\n",
            "733/733 - 2s - loss: 8.9799e-04 - val_loss: 7.8182e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 250/700\n",
            "733/733 - 2s - loss: 8.9533e-04 - val_loss: 7.7798e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 251/700\n",
            "733/733 - 2s - loss: 8.9269e-04 - val_loss: 7.7416e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 252/700\n",
            "733/733 - 2s - loss: 8.9007e-04 - val_loss: 7.7036e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 253/700\n",
            "733/733 - 2s - loss: 8.8747e-04 - val_loss: 7.6658e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 254/700\n",
            "733/733 - 2s - loss: 8.8488e-04 - val_loss: 7.6283e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 255/700\n",
            "733/733 - 2s - loss: 8.8232e-04 - val_loss: 7.5909e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 256/700\n",
            "733/733 - 2s - loss: 8.7978e-04 - val_loss: 7.5537e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 257/700\n",
            "733/733 - 2s - loss: 8.7725e-04 - val_loss: 7.5168e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 258/700\n",
            "733/733 - 2s - loss: 8.7475e-04 - val_loss: 7.4801e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 259/700\n",
            "733/733 - 2s - loss: 8.7226e-04 - val_loss: 7.4436e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 260/700\n",
            "733/733 - 2s - loss: 8.6980e-04 - val_loss: 7.4075e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 261/700\n",
            "733/733 - 2s - loss: 8.6735e-04 - val_loss: 7.3715e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 262/700\n",
            "733/733 - 2s - loss: 8.6493e-04 - val_loss: 7.3358e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 263/700\n",
            "733/733 - 2s - loss: 8.6252e-04 - val_loss: 7.3004e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 264/700\n",
            "733/733 - 2s - loss: 8.6013e-04 - val_loss: 7.2652e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 265/700\n",
            "733/733 - 2s - loss: 8.5776e-04 - val_loss: 7.2303e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 266/700\n",
            "733/733 - 2s - loss: 8.5541e-04 - val_loss: 7.1956e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 267/700\n",
            "733/733 - 2s - loss: 8.5308e-04 - val_loss: 7.1612e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 268/700\n",
            "733/733 - 2s - loss: 8.5077e-04 - val_loss: 7.1271e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 269/700\n",
            "733/733 - 2s - loss: 8.4848e-04 - val_loss: 7.0932e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 270/700\n",
            "733/733 - 2s - loss: 8.4621e-04 - val_loss: 7.0597e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 271/700\n",
            "733/733 - 2s - loss: 8.4395e-04 - val_loss: 7.0264e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 272/700\n",
            "733/733 - 2s - loss: 8.4172e-04 - val_loss: 6.9933e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 273/700\n",
            "733/733 - 2s - loss: 8.3950e-04 - val_loss: 6.9606e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 274/700\n",
            "733/733 - 2s - loss: 8.3731e-04 - val_loss: 6.9281e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 275/700\n",
            "733/733 - 2s - loss: 8.3512e-04 - val_loss: 6.8959e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 276/700\n",
            "733/733 - 2s - loss: 8.3296e-04 - val_loss: 6.8639e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 277/700\n",
            "733/733 - 2s - loss: 8.3082e-04 - val_loss: 6.8323e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 278/700\n",
            "733/733 - 2s - loss: 8.2869e-04 - val_loss: 6.8008e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 279/700\n",
            "733/733 - 2s - loss: 8.2658e-04 - val_loss: 6.7697e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 280/700\n",
            "733/733 - 2s - loss: 8.2449e-04 - val_loss: 6.7388e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 281/700\n",
            "733/733 - 2s - loss: 8.2241e-04 - val_loss: 6.7082e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 282/700\n",
            "733/733 - 2s - loss: 8.2035e-04 - val_loss: 6.6779e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 283/700\n",
            "733/733 - 2s - loss: 8.1831e-04 - val_loss: 6.6478e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 284/700\n",
            "733/733 - 2s - loss: 8.1629e-04 - val_loss: 6.6180e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 285/700\n",
            "733/733 - 2s - loss: 8.1428e-04 - val_loss: 6.5884e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 286/700\n",
            "733/733 - 2s - loss: 8.1228e-04 - val_loss: 6.5591e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 287/700\n",
            "733/733 - 2s - loss: 8.1030e-04 - val_loss: 6.5300e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 288/700\n",
            "733/733 - 2s - loss: 8.0834e-04 - val_loss: 6.5012e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 289/700\n",
            "733/733 - 2s - loss: 8.0639e-04 - val_loss: 6.4726e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 290/700\n",
            "733/733 - 2s - loss: 8.0446e-04 - val_loss: 6.4442e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 291/700\n",
            "733/733 - 2s - loss: 8.0255e-04 - val_loss: 6.4161e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 292/700\n",
            "733/733 - 2s - loss: 8.0064e-04 - val_loss: 6.3882e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 293/700\n",
            "733/733 - 2s - loss: 7.9876e-04 - val_loss: 6.3606e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 294/700\n",
            "733/733 - 2s - loss: 7.9688e-04 - val_loss: 6.3331e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 295/700\n",
            "733/733 - 2s - loss: 7.9502e-04 - val_loss: 6.3059e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 296/700\n",
            "733/733 - 2s - loss: 7.9318e-04 - val_loss: 6.2789e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 297/700\n",
            "733/733 - 2s - loss: 7.9134e-04 - val_loss: 6.2522e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 298/700\n",
            "733/733 - 2s - loss: 7.8953e-04 - val_loss: 6.2257e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 299/700\n",
            "733/733 - 2s - loss: 7.8772e-04 - val_loss: 6.1993e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 300/700\n",
            "733/733 - 2s - loss: 7.8593e-04 - val_loss: 6.1732e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 301/700\n",
            "733/733 - 2s - loss: 7.8415e-04 - val_loss: 6.1473e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 302/700\n",
            "733/733 - 2s - loss: 7.8238e-04 - val_loss: 6.1215e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 303/700\n",
            "733/733 - 2s - loss: 7.8062e-04 - val_loss: 6.0960e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 304/700\n",
            "733/733 - 2s - loss: 7.7888e-04 - val_loss: 6.0707e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 305/700\n",
            "733/733 - 2s - loss: 7.7715e-04 - val_loss: 6.0455e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 306/700\n",
            "733/733 - 2s - loss: 7.7543e-04 - val_loss: 6.0206e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 307/700\n",
            "733/733 - 2s - loss: 7.7372e-04 - val_loss: 5.9958e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 308/700\n",
            "733/733 - 2s - loss: 7.7203e-04 - val_loss: 5.9713e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 309/700\n",
            "733/733 - 2s - loss: 7.7034e-04 - val_loss: 5.9469e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 310/700\n",
            "733/733 - 2s - loss: 7.6867e-04 - val_loss: 5.9227e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 311/700\n",
            "733/733 - 2s - loss: 7.6700e-04 - val_loss: 5.8987e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 312/700\n",
            "733/733 - 2s - loss: 7.6535e-04 - val_loss: 5.8748e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 313/700\n",
            "733/733 - 2s - loss: 7.6371e-04 - val_loss: 5.8512e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 314/700\n",
            "733/733 - 3s - loss: 7.6207e-04 - val_loss: 5.8276e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 315/700\n",
            "733/733 - 2s - loss: 7.6045e-04 - val_loss: 5.8043e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 316/700\n",
            "733/733 - 2s - loss: 7.5884e-04 - val_loss: 5.7811e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 317/700\n",
            "733/733 - 2s - loss: 7.5723e-04 - val_loss: 5.7581e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 318/700\n",
            "733/733 - 2s - loss: 7.5564e-04 - val_loss: 5.7352e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 319/700\n",
            "733/733 - 2s - loss: 7.5406e-04 - val_loss: 5.7125e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 320/700\n",
            "733/733 - 2s - loss: 7.5248e-04 - val_loss: 5.6899e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 321/700\n",
            "733/733 - 2s - loss: 7.5091e-04 - val_loss: 5.6674e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 322/700\n",
            "733/733 - 2s - loss: 7.4936e-04 - val_loss: 5.6451e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 323/700\n",
            "733/733 - 2s - loss: 7.4781e-04 - val_loss: 5.6229e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 324/700\n",
            "733/733 - 2s - loss: 7.4626e-04 - val_loss: 5.6009e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 325/700\n",
            "733/733 - 2s - loss: 7.4473e-04 - val_loss: 5.5790e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 326/700\n",
            "733/733 - 2s - loss: 7.4321e-04 - val_loss: 5.5572e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 327/700\n",
            "733/733 - 2s - loss: 7.4169e-04 - val_loss: 5.5355e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 328/700\n",
            "733/733 - 2s - loss: 7.4018e-04 - val_loss: 5.5140e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 329/700\n",
            "733/733 - 2s - loss: 7.3868e-04 - val_loss: 5.4925e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 330/700\n",
            "733/733 - 2s - loss: 7.3719e-04 - val_loss: 5.4712e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 331/700\n",
            "733/733 - 2s - loss: 7.3571e-04 - val_loss: 5.4499e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 332/700\n",
            "733/733 - 2s - loss: 7.3423e-04 - val_loss: 5.4288e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 333/700\n",
            "733/733 - 3s - loss: 7.3276e-04 - val_loss: 5.4077e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 334/700\n",
            "733/733 - 3s - loss: 7.3129e-04 - val_loss: 5.3868e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 335/700\n",
            "733/733 - 2s - loss: 7.2984e-04 - val_loss: 5.3660e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 336/700\n",
            "733/733 - 2s - loss: 7.2839e-04 - val_loss: 5.3452e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 337/700\n",
            "733/733 - 2s - loss: 7.2695e-04 - val_loss: 5.3245e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 338/700\n",
            "733/733 - 2s - loss: 7.2551e-04 - val_loss: 5.3040e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 339/700\n",
            "733/733 - 2s - loss: 7.2409e-04 - val_loss: 5.2835e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 340/700\n",
            "733/733 - 2s - loss: 7.2267e-04 - val_loss: 5.2631e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 341/700\n",
            "733/733 - 2s - loss: 7.2125e-04 - val_loss: 5.2428e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 342/700\n",
            "733/733 - 2s - loss: 7.1984e-04 - val_loss: 5.2226e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 343/700\n",
            "733/733 - 2s - loss: 7.1844e-04 - val_loss: 5.2025e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 344/700\n",
            "733/733 - 2s - loss: 7.1705e-04 - val_loss: 5.1825e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 345/700\n",
            "733/733 - 2s - loss: 7.1566e-04 - val_loss: 5.1625e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 346/700\n",
            "733/733 - 2s - loss: 7.1428e-04 - val_loss: 5.1427e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 347/700\n",
            "733/733 - 2s - loss: 7.1290e-04 - val_loss: 5.1230e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 348/700\n",
            "733/733 - 2s - loss: 7.1153e-04 - val_loss: 5.1033e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 349/700\n",
            "733/733 - 2s - loss: 7.1017e-04 - val_loss: 5.0838e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 350/700\n",
            "733/733 - 2s - loss: 7.0881e-04 - val_loss: 5.0644e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 351/700\n",
            "733/733 - 2s - loss: 7.0745e-04 - val_loss: 5.0451e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 352/700\n",
            "733/733 - 2s - loss: 7.0610e-04 - val_loss: 5.0259e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 353/700\n",
            "733/733 - 2s - loss: 7.0476e-04 - val_loss: 5.0068e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 354/700\n",
            "733/733 - 2s - loss: 7.0342e-04 - val_loss: 4.9879e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 355/700\n",
            "733/733 - 2s - loss: 7.0209e-04 - val_loss: 4.9691e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 356/700\n",
            "733/733 - 2s - loss: 7.0075e-04 - val_loss: 4.9504e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 357/700\n",
            "733/733 - 2s - loss: 6.9943e-04 - val_loss: 4.9319e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 358/700\n",
            "733/733 - 2s - loss: 6.9810e-04 - val_loss: 4.9136e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 359/700\n",
            "733/733 - 2s - loss: 6.9679e-04 - val_loss: 4.8954e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 360/700\n",
            "733/733 - 2s - loss: 6.9547e-04 - val_loss: 4.8773e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 361/700\n",
            "733/733 - 2s - loss: 6.9416e-04 - val_loss: 4.8595e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 362/700\n",
            "733/733 - 2s - loss: 6.9285e-04 - val_loss: 4.8418e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 363/700\n",
            "733/733 - 2s - loss: 6.9154e-04 - val_loss: 4.8244e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 364/700\n",
            "733/733 - 2s - loss: 6.9024e-04 - val_loss: 4.8071e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 365/700\n",
            "733/733 - 2s - loss: 6.8894e-04 - val_loss: 4.7900e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 366/700\n",
            "733/733 - 2s - loss: 6.8764e-04 - val_loss: 4.7731e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 367/700\n",
            "733/733 - 2s - loss: 6.8634e-04 - val_loss: 4.7564e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 368/700\n",
            "733/733 - 2s - loss: 6.8505e-04 - val_loss: 4.7400e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 369/700\n",
            "733/733 - 2s - loss: 6.8376e-04 - val_loss: 4.7238e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 370/700\n",
            "733/733 - 2s - loss: 6.8247e-04 - val_loss: 4.7078e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 371/700\n",
            "733/733 - 2s - loss: 6.8118e-04 - val_loss: 4.6920e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 372/700\n",
            "733/733 - 2s - loss: 6.7990e-04 - val_loss: 4.6764e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 373/700\n",
            "733/733 - 2s - loss: 6.7862e-04 - val_loss: 4.6611e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 374/700\n",
            "733/733 - 2s - loss: 6.7734e-04 - val_loss: 4.6461e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 375/700\n",
            "733/733 - 2s - loss: 6.7606e-04 - val_loss: 4.6314e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 376/700\n",
            "733/733 - 2s - loss: 6.7479e-04 - val_loss: 4.6168e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 377/700\n",
            "733/733 - 2s - loss: 6.7351e-04 - val_loss: 4.6026e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 378/700\n",
            "733/733 - 2s - loss: 6.7224e-04 - val_loss: 4.5886e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 379/700\n",
            "733/733 - 2s - loss: 6.7097e-04 - val_loss: 4.5749e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 380/700\n",
            "733/733 - 2s - loss: 6.6971e-04 - val_loss: 4.5615e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 381/700\n",
            "733/733 - 2s - loss: 6.6845e-04 - val_loss: 4.5484e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 382/700\n",
            "733/733 - 2s - loss: 6.6719e-04 - val_loss: 4.5355e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 383/700\n",
            "733/733 - 2s - loss: 6.6594e-04 - val_loss: 4.5229e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 384/700\n",
            "733/733 - 2s - loss: 6.6469e-04 - val_loss: 4.5107e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 385/700\n",
            "733/733 - 2s - loss: 6.6344e-04 - val_loss: 4.4987e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 386/700\n",
            "733/733 - 2s - loss: 6.6219e-04 - val_loss: 4.4870e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 387/700\n",
            "733/733 - 2s - loss: 6.6095e-04 - val_loss: 4.4756e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 388/700\n",
            "733/733 - 2s - loss: 6.5972e-04 - val_loss: 4.4645e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 389/700\n",
            "733/733 - 2s - loss: 6.5849e-04 - val_loss: 4.4537e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 390/700\n",
            "733/733 - 2s - loss: 6.5727e-04 - val_loss: 4.4432e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 391/700\n",
            "733/733 - 2s - loss: 6.5605e-04 - val_loss: 4.4330e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 392/700\n",
            "733/733 - 2s - loss: 6.5483e-04 - val_loss: 4.4231e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 393/700\n",
            "733/733 - 2s - loss: 6.5362e-04 - val_loss: 4.4135e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 394/700\n",
            "733/733 - 2s - loss: 6.5242e-04 - val_loss: 4.4042e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 395/700\n",
            "733/733 - 2s - loss: 6.5122e-04 - val_loss: 4.3952e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 396/700\n",
            "733/733 - 2s - loss: 6.5003e-04 - val_loss: 4.3865e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 397/700\n",
            "733/733 - 2s - loss: 6.4885e-04 - val_loss: 4.3781e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 398/700\n",
            "733/733 - 2s - loss: 6.4767e-04 - val_loss: 4.3700e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 399/700\n",
            "733/733 - 2s - loss: 6.4650e-04 - val_loss: 4.3622e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 400/700\n",
            "733/733 - 2s - loss: 6.4534e-04 - val_loss: 4.3547e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 401/700\n",
            "733/733 - 2s - loss: 6.4419e-04 - val_loss: 4.3474e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 402/700\n",
            "733/733 - 2s - loss: 6.4304e-04 - val_loss: 4.3404e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 403/700\n",
            "733/733 - 2s - loss: 6.4190e-04 - val_loss: 4.3337e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 404/700\n",
            "733/733 - 2s - loss: 6.4077e-04 - val_loss: 4.3274e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 405/700\n",
            "733/733 - 2s - loss: 6.3965e-04 - val_loss: 4.3212e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 406/700\n",
            "733/733 - 2s - loss: 6.3853e-04 - val_loss: 4.3154e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 407/700\n",
            "733/733 - 2s - loss: 6.3742e-04 - val_loss: 4.3099e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 408/700\n",
            "733/733 - 2s - loss: 6.3633e-04 - val_loss: 4.3045e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 409/700\n",
            "733/733 - 2s - loss: 6.3524e-04 - val_loss: 4.2995e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 410/700\n",
            "733/733 - 2s - loss: 6.3415e-04 - val_loss: 4.2946e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 411/700\n",
            "733/733 - 2s - loss: 6.3308e-04 - val_loss: 4.2901e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 412/700\n",
            "733/733 - 2s - loss: 6.3202e-04 - val_loss: 4.2858e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 413/700\n",
            "733/733 - 2s - loss: 6.3096e-04 - val_loss: 4.2817e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 414/700\n",
            "733/733 - 2s - loss: 6.2991e-04 - val_loss: 4.2779e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 415/700\n",
            "733/733 - 2s - loss: 6.2888e-04 - val_loss: 4.2743e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 416/700\n",
            "733/733 - 3s - loss: 6.2785e-04 - val_loss: 4.2709e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 417/700\n",
            "733/733 - 3s - loss: 6.2683e-04 - val_loss: 4.2678e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 418/700\n",
            "733/733 - 2s - loss: 6.2582e-04 - val_loss: 4.2649e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 419/700\n",
            "733/733 - 2s - loss: 6.2481e-04 - val_loss: 4.2621e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 420/700\n",
            "733/733 - 2s - loss: 6.2382e-04 - val_loss: 4.2596e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 421/700\n",
            "733/733 - 2s - loss: 6.2283e-04 - val_loss: 4.2573e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 422/700\n",
            "733/733 - 2s - loss: 6.2186e-04 - val_loss: 4.2552e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 423/700\n",
            "733/733 - 2s - loss: 6.2089e-04 - val_loss: 4.2534e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 424/700\n",
            "733/733 - 2s - loss: 6.1993e-04 - val_loss: 4.2517e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 425/700\n",
            "733/733 - 2s - loss: 6.1898e-04 - val_loss: 4.2502e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 426/700\n",
            "733/733 - 2s - loss: 6.1804e-04 - val_loss: 4.2488e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 427/700\n",
            "733/733 - 2s - loss: 6.1710e-04 - val_loss: 4.2477e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 428/700\n",
            "733/733 - 2s - loss: 6.1617e-04 - val_loss: 4.2467e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 429/700\n",
            "733/733 - 2s - loss: 6.1526e-04 - val_loss: 4.2460e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 430/700\n",
            "733/733 - 2s - loss: 6.1435e-04 - val_loss: 4.2454e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 431/700\n",
            "733/733 - 2s - loss: 6.1345e-04 - val_loss: 4.2449e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 432/700\n",
            "733/733 - 2s - loss: 6.1255e-04 - val_loss: 4.2447e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 433/700\n",
            "733/733 - 2s - loss: 6.1167e-04 - val_loss: 4.2446e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 434/700\n",
            "733/733 - 3s - loss: 6.1079e-04 - val_loss: 4.2446e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 435/700\n",
            "733/733 - 2s - loss: 6.0992e-04 - val_loss: 4.2448e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 436/700\n",
            "733/733 - 2s - loss: 6.0905e-04 - val_loss: 4.2452e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 437/700\n",
            "733/733 - 2s - loss: 6.0820e-04 - val_loss: 4.2457e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 438/700\n",
            "733/733 - 2s - loss: 6.0735e-04 - val_loss: 4.2463e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 439/700\n",
            "733/733 - 2s - loss: 6.0651e-04 - val_loss: 4.2471e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 440/700\n",
            "733/733 - 2s - loss: 6.0567e-04 - val_loss: 4.2481e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 441/700\n",
            "733/733 - 2s - loss: 6.0484e-04 - val_loss: 4.2491e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 442/700\n",
            "733/733 - 2s - loss: 6.0402e-04 - val_loss: 4.2504e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 443/700\n",
            "733/733 - 2s - loss: 6.0321e-04 - val_loss: 4.2517e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 444/700\n",
            "733/733 - 2s - loss: 6.0240e-04 - val_loss: 4.2532e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 445/700\n",
            "733/733 - 2s - loss: 6.0160e-04 - val_loss: 4.2548e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 446/700\n",
            "733/733 - 2s - loss: 6.0081e-04 - val_loss: 4.2565e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 447/700\n",
            "733/733 - 2s - loss: 6.0002e-04 - val_loss: 4.2584e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 448/700\n",
            "733/733 - 2s - loss: 5.9924e-04 - val_loss: 4.2603e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 449/700\n",
            "733/733 - 2s - loss: 5.9846e-04 - val_loss: 4.2624e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 450/700\n",
            "733/733 - 2s - loss: 5.9769e-04 - val_loss: 4.2646e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 451/700\n",
            "733/733 - 2s - loss: 5.9693e-04 - val_loss: 4.2669e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 452/700\n",
            "733/733 - 2s - loss: 5.9617e-04 - val_loss: 4.2693e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 453/700\n",
            "733/733 - 2s - loss: 5.9542e-04 - val_loss: 4.2719e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 454/700\n",
            "733/733 - 2s - loss: 5.9467e-04 - val_loss: 4.2745e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 455/700\n",
            "733/733 - 2s - loss: 5.9393e-04 - val_loss: 4.2772e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 456/700\n",
            "733/733 - 2s - loss: 5.9319e-04 - val_loss: 4.2801e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 457/700\n",
            "733/733 - 2s - loss: 5.9246e-04 - val_loss: 4.2830e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 458/700\n",
            "733/733 - 2s - loss: 5.9174e-04 - val_loss: 4.2860e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 459/700\n",
            "733/733 - 2s - loss: 5.9102e-04 - val_loss: 4.2891e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 460/700\n",
            "733/733 - 2s - loss: 5.9030e-04 - val_loss: 4.2924e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 461/700\n",
            "733/733 - 2s - loss: 5.8959e-04 - val_loss: 4.2957e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 462/700\n",
            "733/733 - 2s - loss: 5.8888e-04 - val_loss: 4.2990e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 463/700\n",
            "733/733 - 2s - loss: 5.8818e-04 - val_loss: 4.3025e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 464/700\n",
            "733/733 - 2s - loss: 5.8748e-04 - val_loss: 4.3060e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 465/700\n",
            "733/733 - 2s - loss: 5.8679e-04 - val_loss: 4.3096e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 466/700\n",
            "733/733 - 2s - loss: 5.8610e-04 - val_loss: 4.3133e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 467/700\n",
            "733/733 - 2s - loss: 5.8541e-04 - val_loss: 4.3171e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 468/700\n",
            "733/733 - 2s - loss: 5.8473e-04 - val_loss: 4.3209e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 469/700\n",
            "733/733 - 2s - loss: 5.8406e-04 - val_loss: 4.3248e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 470/700\n",
            "733/733 - 2s - loss: 5.8339e-04 - val_loss: 4.3288e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 471/700\n",
            "733/733 - 2s - loss: 5.8272e-04 - val_loss: 4.3328e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 472/700\n",
            "733/733 - 2s - loss: 5.8205e-04 - val_loss: 4.3370e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 473/700\n",
            "733/733 - 2s - loss: 5.8139e-04 - val_loss: 4.3411e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 474/700\n",
            "733/733 - 2s - loss: 5.8074e-04 - val_loss: 4.3454e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 475/700\n",
            "733/733 - 2s - loss: 5.8008e-04 - val_loss: 4.3496e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 476/700\n",
            "733/733 - 2s - loss: 5.7943e-04 - val_loss: 4.3539e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 477/700\n",
            "733/733 - 2s - loss: 5.7878e-04 - val_loss: 4.3583e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 478/700\n",
            "733/733 - 2s - loss: 5.7814e-04 - val_loss: 4.3627e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 479/700\n",
            "733/733 - 2s - loss: 5.7750e-04 - val_loss: 4.3672e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 480/700\n",
            "733/733 - 2s - loss: 5.7687e-04 - val_loss: 4.3717e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 481/700\n",
            "733/733 - 2s - loss: 5.7623e-04 - val_loss: 4.3763e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 482/700\n",
            "733/733 - 2s - loss: 5.7560e-04 - val_loss: 4.3809e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 483/700\n",
            "733/733 - 2s - loss: 5.7497e-04 - val_loss: 4.3855e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 484/700\n",
            "733/733 - 2s - loss: 5.7435e-04 - val_loss: 4.3902e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 485/700\n",
            "733/733 - 2s - loss: 5.7373e-04 - val_loss: 4.3949e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 486/700\n",
            "733/733 - 2s - loss: 5.7311e-04 - val_loss: 4.3996e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 487/700\n",
            "733/733 - 2s - loss: 5.7249e-04 - val_loss: 4.4044e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 488/700\n",
            "733/733 - 2s - loss: 5.7188e-04 - val_loss: 4.4092e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 489/700\n",
            "733/733 - 2s - loss: 5.7126e-04 - val_loss: 4.4140e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 490/700\n",
            "733/733 - 2s - loss: 5.7066e-04 - val_loss: 4.4189e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 491/700\n",
            "733/733 - 2s - loss: 5.7005e-04 - val_loss: 4.4237e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 492/700\n",
            "733/733 - 2s - loss: 5.6944e-04 - val_loss: 4.4286e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 493/700\n",
            "733/733 - 2s - loss: 5.6884e-04 - val_loss: 4.4335e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 494/700\n",
            "733/733 - 2s - loss: 5.6824e-04 - val_loss: 4.4384e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 495/700\n",
            "733/733 - 2s - loss: 5.6765e-04 - val_loss: 4.4434e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 496/700\n",
            "733/733 - 2s - loss: 5.6705e-04 - val_loss: 4.4483e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 497/700\n",
            "733/733 - 2s - loss: 5.6646e-04 - val_loss: 4.4533e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 498/700\n",
            "733/733 - 2s - loss: 5.6587e-04 - val_loss: 4.4583e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 499/700\n",
            "733/733 - 2s - loss: 5.6528e-04 - val_loss: 4.4633e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 500/700\n",
            "733/733 - 2s - loss: 5.6469e-04 - val_loss: 4.4683e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 501/700\n",
            "733/733 - 2s - loss: 5.6410e-04 - val_loss: 4.4732e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 502/700\n",
            "733/733 - 2s - loss: 5.6352e-04 - val_loss: 4.4782e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 503/700\n",
            "733/733 - 2s - loss: 5.6294e-04 - val_loss: 4.4832e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 504/700\n",
            "733/733 - 2s - loss: 5.6235e-04 - val_loss: 4.4882e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 505/700\n",
            "733/733 - 2s - loss: 5.6178e-04 - val_loss: 4.4932e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 506/700\n",
            "733/733 - 2s - loss: 5.6120e-04 - val_loss: 4.4982e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 507/700\n",
            "733/733 - 2s - loss: 5.6062e-04 - val_loss: 4.5032e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 508/700\n",
            "733/733 - 2s - loss: 5.6005e-04 - val_loss: 4.5081e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 509/700\n",
            "733/733 - 2s - loss: 5.5948e-04 - val_loss: 4.5130e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 510/700\n",
            "733/733 - 2s - loss: 5.5890e-04 - val_loss: 4.5180e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 511/700\n",
            "733/733 - 2s - loss: 5.5833e-04 - val_loss: 4.5229e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 512/700\n",
            "733/733 - 2s - loss: 5.5776e-04 - val_loss: 4.5278e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 513/700\n",
            "733/733 - 2s - loss: 5.5720e-04 - val_loss: 4.5326e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 514/700\n",
            "733/733 - 2s - loss: 5.5663e-04 - val_loss: 4.5375e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 515/700\n",
            "733/733 - 2s - loss: 5.5606e-04 - val_loss: 4.5424e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 516/700\n",
            "733/733 - 2s - loss: 5.5550e-04 - val_loss: 4.5472e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 517/700\n",
            "733/733 - 2s - loss: 5.5494e-04 - val_loss: 4.5520e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 518/700\n",
            "733/733 - 3s - loss: 5.5438e-04 - val_loss: 4.5568e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 519/700\n",
            "733/733 - 2s - loss: 5.5381e-04 - val_loss: 4.5615e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 520/700\n",
            "733/733 - 2s - loss: 5.5325e-04 - val_loss: 4.5662e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 521/700\n",
            "733/733 - 2s - loss: 5.5270e-04 - val_loss: 4.5709e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 522/700\n",
            "733/733 - 2s - loss: 5.5214e-04 - val_loss: 4.5755e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 523/700\n",
            "733/733 - 2s - loss: 5.5158e-04 - val_loss: 4.5801e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 524/700\n",
            "733/733 - 2s - loss: 5.5102e-04 - val_loss: 4.5847e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 525/700\n",
            "733/733 - 2s - loss: 5.5047e-04 - val_loss: 4.5892e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 526/700\n",
            "733/733 - 2s - loss: 5.4991e-04 - val_loss: 4.5937e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 527/700\n",
            "733/733 - 2s - loss: 5.4936e-04 - val_loss: 4.5982e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 528/700\n",
            "733/733 - 2s - loss: 5.4880e-04 - val_loss: 4.6026e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 529/700\n",
            "733/733 - 2s - loss: 5.4825e-04 - val_loss: 4.6069e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 530/700\n",
            "733/733 - 2s - loss: 5.4770e-04 - val_loss: 4.6112e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 531/700\n",
            "733/733 - 2s - loss: 5.4715e-04 - val_loss: 4.6155e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 532/700\n",
            "733/733 - 2s - loss: 5.4660e-04 - val_loss: 4.6198e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 533/700\n",
            "733/733 - 2s - loss: 5.4605e-04 - val_loss: 4.6240e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 534/700\n",
            "733/733 - 2s - loss: 5.4550e-04 - val_loss: 4.6281e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 535/700\n",
            "733/733 - 3s - loss: 5.4495e-04 - val_loss: 4.6322e-04 - 3s/epoch - 3ms/step\n",
            "Epoch 536/700\n",
            "733/733 - 3s - loss: 5.4440e-04 - val_loss: 4.6362e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 537/700\n",
            "733/733 - 2s - loss: 5.4386e-04 - val_loss: 4.6402e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 538/700\n",
            "733/733 - 2s - loss: 5.4331e-04 - val_loss: 4.6442e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 539/700\n",
            "733/733 - 2s - loss: 5.4276e-04 - val_loss: 4.6481e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 540/700\n",
            "733/733 - 2s - loss: 5.4222e-04 - val_loss: 4.6519e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 541/700\n",
            "733/733 - 2s - loss: 5.4167e-04 - val_loss: 4.6556e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 542/700\n",
            "733/733 - 2s - loss: 5.4112e-04 - val_loss: 4.6594e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 543/700\n",
            "733/733 - 2s - loss: 5.4058e-04 - val_loss: 4.6630e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 544/700\n",
            "733/733 - 2s - loss: 5.4004e-04 - val_loss: 4.6666e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 545/700\n",
            "733/733 - 2s - loss: 5.3949e-04 - val_loss: 4.6701e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 546/700\n",
            "733/733 - 2s - loss: 5.3895e-04 - val_loss: 4.6736e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 547/700\n",
            "733/733 - 2s - loss: 5.3841e-04 - val_loss: 4.6770e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 548/700\n",
            "733/733 - 2s - loss: 5.3786e-04 - val_loss: 4.6804e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 549/700\n",
            "733/733 - 2s - loss: 5.3732e-04 - val_loss: 4.6837e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 550/700\n",
            "733/733 - 2s - loss: 5.3678e-04 - val_loss: 4.6869e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 551/700\n",
            "733/733 - 2s - loss: 5.3624e-04 - val_loss: 4.6901e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 552/700\n",
            "733/733 - 2s - loss: 5.3570e-04 - val_loss: 4.6932e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 553/700\n",
            "733/733 - 2s - loss: 5.3516e-04 - val_loss: 4.6962e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 554/700\n",
            "733/733 - 2s - loss: 5.3462e-04 - val_loss: 4.6991e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 555/700\n",
            "733/733 - 2s - loss: 5.3408e-04 - val_loss: 4.7020e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 556/700\n",
            "733/733 - 2s - loss: 5.3354e-04 - val_loss: 4.7049e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 557/700\n",
            "733/733 - 2s - loss: 5.3300e-04 - val_loss: 4.7076e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 558/700\n",
            "733/733 - 2s - loss: 5.3246e-04 - val_loss: 4.7103e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 559/700\n",
            "733/733 - 2s - loss: 5.3192e-04 - val_loss: 4.7129e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 560/700\n",
            "733/733 - 2s - loss: 5.3138e-04 - val_loss: 4.7155e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 561/700\n",
            "733/733 - 2s - loss: 5.3085e-04 - val_loss: 4.7180e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 562/700\n",
            "733/733 - 2s - loss: 5.3031e-04 - val_loss: 4.7204e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 563/700\n",
            "733/733 - 2s - loss: 5.2977e-04 - val_loss: 4.7227e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 564/700\n",
            "733/733 - 2s - loss: 5.2924e-04 - val_loss: 4.7250e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 565/700\n",
            "733/733 - 2s - loss: 5.2870e-04 - val_loss: 4.7272e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 566/700\n",
            "733/733 - 2s - loss: 5.2817e-04 - val_loss: 4.7293e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 567/700\n",
            "733/733 - 2s - loss: 5.2763e-04 - val_loss: 4.7314e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 568/700\n",
            "733/733 - 2s - loss: 5.2710e-04 - val_loss: 4.7333e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 569/700\n",
            "733/733 - 2s - loss: 5.2656e-04 - val_loss: 4.7352e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 570/700\n",
            "733/733 - 2s - loss: 5.2603e-04 - val_loss: 4.7371e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 571/700\n",
            "733/733 - 2s - loss: 5.2550e-04 - val_loss: 4.7388e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 572/700\n",
            "733/733 - 2s - loss: 5.2496e-04 - val_loss: 4.7405e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 573/700\n",
            "733/733 - 2s - loss: 5.2443e-04 - val_loss: 4.7421e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 574/700\n",
            "733/733 - 2s - loss: 5.2390e-04 - val_loss: 4.7436e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 575/700\n",
            "733/733 - 2s - loss: 5.2337e-04 - val_loss: 4.7451e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 576/700\n",
            "733/733 - 2s - loss: 5.2284e-04 - val_loss: 4.7465e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 577/700\n",
            "733/733 - 2s - loss: 5.2231e-04 - val_loss: 4.7479e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 578/700\n",
            "733/733 - 2s - loss: 5.2178e-04 - val_loss: 4.7491e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 579/700\n",
            "733/733 - 2s - loss: 5.2125e-04 - val_loss: 4.7503e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 580/700\n",
            "733/733 - 2s - loss: 5.2072e-04 - val_loss: 4.7514e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 581/700\n",
            "733/733 - 2s - loss: 5.2020e-04 - val_loss: 4.7524e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 582/700\n",
            "733/733 - 2s - loss: 5.1967e-04 - val_loss: 4.7534e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 583/700\n",
            "733/733 - 2s - loss: 5.1914e-04 - val_loss: 4.7543e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 584/700\n",
            "733/733 - 2s - loss: 5.1862e-04 - val_loss: 4.7551e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 585/700\n",
            "733/733 - 2s - loss: 5.1809e-04 - val_loss: 4.7558e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 586/700\n",
            "733/733 - 2s - loss: 5.1757e-04 - val_loss: 4.7565e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 587/700\n",
            "733/733 - 2s - loss: 5.1704e-04 - val_loss: 4.7570e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 588/700\n",
            "733/733 - 2s - loss: 5.1652e-04 - val_loss: 4.7575e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 589/700\n",
            "733/733 - 2s - loss: 5.1600e-04 - val_loss: 4.7580e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 590/700\n",
            "733/733 - 2s - loss: 5.1548e-04 - val_loss: 4.7583e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 591/700\n",
            "733/733 - 2s - loss: 5.1496e-04 - val_loss: 4.7586e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 592/700\n",
            "733/733 - 2s - loss: 5.1444e-04 - val_loss: 4.7589e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 593/700\n",
            "733/733 - 2s - loss: 5.1392e-04 - val_loss: 4.7590e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 594/700\n",
            "733/733 - 2s - loss: 5.1340e-04 - val_loss: 4.7591e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 595/700\n",
            "733/733 - 2s - loss: 5.1288e-04 - val_loss: 4.7591e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 596/700\n",
            "733/733 - 2s - loss: 5.1236e-04 - val_loss: 4.7591e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 597/700\n",
            "733/733 - 2s - loss: 5.1185e-04 - val_loss: 4.7590e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 598/700\n",
            "733/733 - 2s - loss: 5.1133e-04 - val_loss: 4.7588e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 599/700\n",
            "733/733 - 2s - loss: 5.1082e-04 - val_loss: 4.7585e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 600/700\n",
            "733/733 - 2s - loss: 5.1030e-04 - val_loss: 4.7582e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 601/700\n",
            "733/733 - 2s - loss: 5.0979e-04 - val_loss: 4.7578e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 602/700\n",
            "733/733 - 2s - loss: 5.0928e-04 - val_loss: 4.7574e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 603/700\n",
            "733/733 - 2s - loss: 5.0877e-04 - val_loss: 4.7569e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 604/700\n",
            "733/733 - 2s - loss: 5.0826e-04 - val_loss: 4.7563e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 605/700\n",
            "733/733 - 2s - loss: 5.0775e-04 - val_loss: 4.7556e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 606/700\n",
            "733/733 - 2s - loss: 5.0724e-04 - val_loss: 4.7549e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 607/700\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-6af463051e4e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;31m# Train the model for one epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m history = model.fit(train_X, train_y, callbacks=[early_stopping, mcp_save],\n\u001b[0m\u001b[1;32m     40\u001b[0m                 \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m                     shuffle=False)\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1407\u001b[0m                 _r=1):\n\u001b[1;32m   1408\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1410\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2451\u001b[0m       (graph_function,\n\u001b[1;32m   2452\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2453\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2454\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1858\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1859\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1860\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1861\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1862\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    495\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 497\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    498\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"  \n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
        "os.environ['PYTHONHASHSEED'] = '0'\n",
        "np.random.seed(42)\n",
        "np.random.seed(12345)\n",
        "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
        "\n",
        "from keras import backend as K\n",
        "tf.random.set_seed(1234)\n",
        "\n",
        "sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
        "K.set_session(sess)\n",
        "\n",
        "# fit the model\n",
        "neurons= [112]#12 \n",
        "n_epochs=700#186\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(neurons[0], activation=\"tanh\", input_shape=(timesteps, n_features)))\n",
        "model.add(Dense(steps_ahead)) # output layer\n",
        "model.compile(loss='mean_squared_error', optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4))\n",
        "\n",
        "# # early stopping to return the best model\n",
        "early_stopping = EarlyStopping(monitor='loss', patience=2, verbose=2, restore_best_weights=True, mode='min')\n",
        "# save the best weights if training is interrupted\n",
        "mcp_save = ModelCheckpoint('.mdl_wts.hdf5', save_best_only=True, monitor='val_loss', mode='min') \n",
        "#reduce_lr_loss = ReduceLROnPlateau(monitor='loss', factor=0.1, patience=5, verbose=1, min_delta=1e-4, mode='min')\n",
        "\n",
        "# Set the initial validation loss to a large value\n",
        "best_val_loss = float('inf')\n",
        "\n",
        "# Set the initial and total number of epochs\n",
        "initial_epoch = 1\n",
        "n_epochs = 1200\n",
        "loss_tracking = list()\n",
        "\n",
        "# Run the training loop\n",
        "\n",
        "# Train the model for one epoch\n",
        "history = model.fit(train_X, train_y, callbacks=[early_stopping, mcp_save],\n",
        "                epochs=1, batch_size=2, validation_data=(test_X, test_y), verbose=2,\n",
        "                    shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "1EvEswvoTXy5",
        "outputId": "a442985a-9c0b-4c21-a0b6-236fcb728e7b"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-d9caaaaf01a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;31m# Train the model for one epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m history = model.fit(train_X, train_y, callbacks=[early_stopping, mcp_save],\n\u001b[0m\u001b[1;32m     41\u001b[0m                 \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m                     shuffle=False)\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1407\u001b[0m                 _r=1):\n\u001b[1;32m   1408\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1410\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    978\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 980\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    981\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    982\u001b[0m       _, _, filtered_flat_args = (\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2450\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2451\u001b[0m       (graph_function,\n\u001b[0;32m-> 2452\u001b[0;31m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0m\u001b[1;32m   2453\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m   2454\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2709\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache_key\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_placeholder_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2710\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2711\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2712\u001b[0m           self._function_cache.add(cache_key, cache_key_deletion_observer,\n\u001b[1;32m   2713\u001b[0m                                    graph_function)\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2625\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2626\u001b[0m     graph_function = ConcreteFunction(\n\u001b[0;32m-> 2627\u001b[0;31m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m   2628\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2629\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1139\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1141\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    675\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 677\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    678\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1114\u001b[0m           \u001b[0;31m# TODO(mdan): Push this block higher in tf.function's call stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1115\u001b[0m           \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1116\u001b[0;31m             return autograph.converted_call(\n\u001b[0m\u001b[1;32m   1117\u001b[0m                 \u001b[0moriginal_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1118\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    437\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    329\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_in_allowlist_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Allowlisted %s: from cache'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_status_ctx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDISABLED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    457\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 459\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mstep_function\u001b[0;34m(model, iterator)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             run_step, jit_compile=True, reduce_retracing=True)\n\u001b[1;32m   1039\u001b[0m       \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute_strategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m       outputs = reduce_per_replica(\n\u001b[1;32m   1042\u001b[0m           outputs, self.distribute_strategy, reduction='first')\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1310\u001b[0m       fn = autograph.tf_convert(\n\u001b[1;32m   1311\u001b[0m           fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[0;32m-> 1312\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extended\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1314\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mcall_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   2886\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2887\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2888\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2889\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2890\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   3687\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3688\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mReplicaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplica_id_in_sync_group\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3689\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3691\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_reduce_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestinations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    687\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconversion_ctx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 689\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    690\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_requested\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_allowlisted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m   \u001b[0;31m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mrun_step\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1029\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mrun_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1030\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1031\u001b[0m         \u001b[0;31m# Ensure counter is updated only if `train_step` succeeds.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_minimum_control_deps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    891\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_target_and_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    892\u001b[0m     \u001b[0;31m# Run backwards pass.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 893\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    894\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(self, loss, var_list, grad_loss, name, tape)\u001b[0m\n\u001b[1;32m    535\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m     \"\"\"\n\u001b[0;32m--> 537\u001b[0;31m     grads_and_vars = self._compute_gradients(\n\u001b[0m\u001b[1;32m    538\u001b[0m         loss, var_list=var_list, grad_loss=grad_loss, tape=tape)\n\u001b[1;32m    539\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36m_compute_gradients\u001b[0;34m(self, loss, var_list, grad_loss, tape)\u001b[0m\n\u001b[1;32m    588\u001b[0m     \u001b[0mvar_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/gradients\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m       \u001b[0mgrads_and_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m     self._assert_valid_dtypes([\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36m_get_gradients\u001b[0;34m(self, tape, loss, var_list, grad_loss)\u001b[0m\n\u001b[1;32m    469\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_get_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m     \u001b[0;34m\"\"\"Called in `minimize` to compute gradients from loss.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 471\u001b[0;31m     \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    472\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                           for x in output_gradients]\n\u001b[1;32m   1099\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m     flat_grad = imperative_grad.imperative_grad(\n\u001b[0m\u001b[1;32m   1101\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m         \u001b[0mflat_targets\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     65\u001b[0m         \"Unknown value for unconnected_gradients: %r\" % unconnected_gradients)\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m   return pywrap_tfe.TFE_Py_TapeGradient(\n\u001b[0m\u001b[1;32m     68\u001b[0m       \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_backward_function\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    748\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_backward_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m       \u001b[0mcall_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 750\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rewrite_forward_and_call_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    751\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_backward_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    752\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_rewrite_forward_and_call_backward\u001b[0;34m(self, op, *doutputs)\u001b[0m\n\u001b[1;32m    664\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_rewrite_forward_and_call_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mdoutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m     \u001b[0;34m\"\"\"Add outputs to the forward call and feed them to the grad function.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 666\u001b[0;31m     \u001b[0mforward_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackwards_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    667\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mbackwards_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mbackwards_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstructured_outputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mforward_backward\u001b[0;34m(self, num_doutputs)\u001b[0m\n\u001b[1;32m    597\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mforward_backward\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mforward_backward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m     \u001b[0mforward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_construct_forward_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_doutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cached_function_pairs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnum_doutputs\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_construct_forward_backward\u001b[0;34m(self, num_doutputs)\u001b[0m\n\u001b[1;32m    640\u001b[0m       backwards_graph = func_graph_module.FuncGraph(\n\u001b[1;32m    641\u001b[0m           _backward_name(self._func_graph.name))\n\u001b[0;32m--> 642\u001b[0;31m       func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m    643\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbackwards_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m           \u001b[0mpython_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_backprop_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1139\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1141\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_backprop_function\u001b[0;34m(*grad_ys)\u001b[0m\n\u001b[1;32m    631\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_backprop_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mgrad_ys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m         return gradients_util._GradientsHelper(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    634\u001b[0m             \u001b[0mtrainable_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gradients_util.py\u001b[0m in \u001b[0;36m_GradientsHelper\u001b[0;34m(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients, unconnected_gradients, src_graph)\u001b[0m\n\u001b[1;32m    693\u001b[0m                 \u001b[0;31m# If grad_fn was found, do not use SymbolicGradient even for\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m                 \u001b[0;31m# functions.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 695\u001b[0;31m                 in_grads = _MaybeCompile(grad_scope, op, func_call,\n\u001b[0m\u001b[1;32m    696\u001b[0m                                          lambda: grad_fn(op, *out_grads))\n\u001b[1;32m    697\u001b[0m               \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gradients_util.py\u001b[0m in \u001b[0;36m_MaybeCompile\u001b[0;34m(scope, op, func, grad_fn)\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mxla_compile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Exit early\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m   \u001b[0;31m# If the gradients are supposed to be compiled separately, we give them a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gradients_util.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    694\u001b[0m                 \u001b[0;31m# functions.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m                 in_grads = _MaybeCompile(grad_scope, op, func_call,\n\u001b[0;32m--> 696\u001b[0;31m                                          lambda: grad_fn(op, *out_grads))\n\u001b[0m\u001b[1;32m    697\u001b[0m               \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m                 \u001b[0;31m# For function call ops, we add a 'SymbolicGradient'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/while_v2.py\u001b[0m in \u001b[0;36m_WhileGrad\u001b[0;34m(op, *grads)\u001b[0m\n\u001b[1;32m    382\u001b[0m       body_graph.outputs, body_graph.inputs, grads) if grad is not None])\n\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m   body_grad_graph, args = _create_grad_func(\n\u001b[0m\u001b[1;32m    385\u001b[0m       \u001b[0mys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_none_grads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcond_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m       \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique_grad_fn_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaximum_iterations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/while_v2.py\u001b[0m in \u001b[0;36m_create_grad_func\u001b[0;34m(ys, xs, grads, cond_graph, body_graph, name, while_op, maximum_iterations, stateful_parallelism)\u001b[0m\n\u001b[1;32m    684\u001b[0m   \u001b[0;31m# Note: The returned function does not have `args` in the list of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m   \u001b[0;31m# `external_captures`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m   grad_func_graph = func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m    687\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m       \u001b[0;32mlambda\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_grad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1139\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1141\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/while_v2.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    686\u001b[0m   grad_func_graph = func_graph_module.func_graph_from_py_func(\n\u001b[1;32m    687\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m       \u001b[0;32mlambda\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_grad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m       func_graph=_WhileBodyGradFuncGraph(name, cond_graph, body_graph,\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/while_v2.py\u001b[0m in \u001b[0;36m_grad_fn\u001b[0;34m(ys, xs, args, func_graph)\u001b[0m\n\u001b[1;32m    742\u001b[0m   \u001b[0;31m# after the forward While op has been rewritten in _resolve_grad_captures.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m   \u001b[0;31m# TODO(srbs): Mark GradientsHelper as public?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m   grad_outs = gradients_util._GradientsHelper(\n\u001b[0m\u001b[1;32m    745\u001b[0m       \u001b[0mys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_ys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgrad_ys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m       unconnected_gradients=\"zero\")\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gradients_util.py\u001b[0m in \u001b[0;36m_GradientsHelper\u001b[0;34m(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients, unconnected_gradients, src_graph)\u001b[0m\n\u001b[1;32m    693\u001b[0m                 \u001b[0;31m# If grad_fn was found, do not use SymbolicGradient even for\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m                 \u001b[0;31m# functions.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 695\u001b[0;31m                 in_grads = _MaybeCompile(grad_scope, op, func_call,\n\u001b[0m\u001b[1;32m    696\u001b[0m                                          lambda: grad_fn(op, *out_grads))\n\u001b[1;32m    697\u001b[0m               \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gradients_util.py\u001b[0m in \u001b[0;36m_MaybeCompile\u001b[0;34m(scope, op, func, grad_fn)\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mxla_compile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Exit early\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m   \u001b[0;31m# If the gradients are supposed to be compiled separately, we give them a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gradients_util.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    694\u001b[0m                 \u001b[0;31m# functions.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m                 in_grads = _MaybeCompile(grad_scope, op, func_call,\n\u001b[0;32m--> 696\u001b[0;31m                                          lambda: grad_fn(op, *out_grads))\n\u001b[0m\u001b[1;32m    697\u001b[0m               \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m                 \u001b[0;31m# For function call ops, we add a 'SymbolicGradient'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/list_ops.py\u001b[0m in \u001b[0;36m_TensorListGetItemGrad\u001b[0;34m(op, ditem)\u001b[0m\n\u001b[1;32m    288\u001b[0m   \u001b[0mlist_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_list_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor_list_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m   list_grad = gen_list_ops.tensor_list_set_item(\n\u001b[0;32m--> 290\u001b[0;31m       gen_list_ops.tensor_list_reserve(\n\u001b[0m\u001b[1;32m    291\u001b[0m           gen_list_ops.tensor_list_element_shape(op.inputs[0],\n\u001b[1;32m    292\u001b[0m                                                  shape_type=dtypes.int32),\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gen_list_ops.py\u001b[0m in \u001b[0;36mtensor_list_reserve\u001b[0;34m(element_shape, num_elements, element_dtype, name)\u001b[0m\n\u001b[1;32m    885\u001b[0m   \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m   \u001b[0melement_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melement_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"element_dtype\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 887\u001b[0;31m   _, _, _op, _outputs = _op_def_library._apply_op_helper(\n\u001b[0m\u001b[1;32m    888\u001b[0m         \u001b[0;34m\"TensorListReserve\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melement_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0melement_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    889\u001b[0m                              \u001b[0mnum_elements\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_elements\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    795\u001b[0m       \u001b[0;31m# Add Op to graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m       \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 797\u001b[0;31m       op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n\u001b[0m\u001b[1;32m    798\u001b[0m                                  \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m                                  attrs=attr_protos, op_def=op_def)\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/while_v2.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m   1033\u001b[0m           compute_device=compute_device)\n\u001b[1;32m   1034\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1035\u001b[0;31m     return super(_WhileBodyGradFuncGraph, self)._create_op_internal(\n\u001b[0m\u001b[1;32m   1036\u001b[0m         \u001b[0mop_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1037\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m    690\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mctxt\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctxt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"AddValue\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m         \u001b[0minp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctxt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAddValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 692\u001b[0;31m       \u001b[0minp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    693\u001b[0m       \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m     return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mcapture\u001b[0;34m(self, tensor, name, shape)\u001b[0m\n\u001b[1;32m    757\u001b[0m               f\"it was defined in {tensor.graph}, which is out of scope.\")\n\u001b[1;32m    758\u001b[0m         \u001b[0minner_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mouter_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_capture_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/while_v2.py\u001b[0m in \u001b[0;36m_capture_helper\u001b[0;34m(self, tensor, name)\u001b[0m\n\u001b[1;32m   1196\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mouter_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1197\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear_control_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1198\u001b[0;31m           tensor_list = list_ops.empty_tensor_list(\n\u001b[0m\u001b[1;32m   1199\u001b[0m               \u001b[0melement_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1200\u001b[0m               \u001b[0melement_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/list_ops.py\u001b[0m in \u001b[0;36mempty_tensor_list\u001b[0;34m(element_shape, element_dtype, max_num_elements, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mmax_num_elements\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m   return gen_list_ops.empty_tensor_list(\n\u001b[0m\u001b[1;32m     55\u001b[0m       \u001b[0melement_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_build_element_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melement_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m       \u001b[0melement_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0melement_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gen_list_ops.py\u001b[0m in \u001b[0;36mempty_tensor_list\u001b[0;34m(element_shape, max_num_elements, element_dtype, name)\u001b[0m\n\u001b[1;32m     61\u001b[0m   \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m   \u001b[0melement_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melement_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"element_dtype\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m   _, _, _op, _outputs = _op_def_library._apply_op_helper(\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;34m\"EmptyTensorList\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melement_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0melement_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m                            \u001b[0mmax_num_elements\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_num_elements\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    775\u001b[0m   \u001b[0;31m# Requires that op_def has passed validation (using the C++\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m   \u001b[0;31m# ValidateOpDef() from ../framework/op_def_util.h).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m   \u001b[0;32mwith\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mscope\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m       _ExtractInputsAndAttrs(op_type_name, op_def, allowed_list_attr_map,\n",
            "\u001b[0;32m/usr/lib/python3.8/contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36minner_cm\u001b[0;34m()\u001b[0m\n\u001b[1;32m    492\u001b[0m       \u001b[0mold_device_stack\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_device_function_stack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m       if (not context.executing_eagerly() and\n\u001b[0;32m--> 494\u001b[0;31m           (device_stack_has_callable(graph._device_function_stack) or\n\u001b[0m\u001b[1;32m    495\u001b[0m            (self._distribution_strategy_stack and\n\u001b[1;32m    496\u001b[0m             not ops.executing_eagerly_outside_functions()))):\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mdevice_stack_has_callable\u001b[0;34m(device_stack)\u001b[0m\n\u001b[1;32m   1212\u001b[0m   return any(\n\u001b[1;32m   1213\u001b[0m       \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_device_name_or_function\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1214\u001b[0;31m       for spec in device_stack.peek_objs())\n\u001b[0m\u001b[1;32m   1215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/traceable_stack.py\u001b[0m in \u001b[0;36mpeek_objs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    109\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mpeek_objs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;34m\"\"\"Return iterator over stored objects ordered newest to oldest.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mt_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt_obj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreversed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mpeek_traceable_objs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# restore the model\n",
        "import tensorflow as tf\n",
        "# model = tf.keras.models.load_model('best_model_10.h5')\n",
        "scores = model.evaluate(test_X, test_y, verbose=0)\n",
        "scores # validation loss for the saved model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-IdG8pB41S0",
        "outputId": "308d1421-8196-4cb8-f36c-3557285c8d55"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0004244557931087911"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # continue training if interrupted \n",
        "\n",
        "# model.compile(loss='mean_squared_error', optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4))\n",
        "\n",
        "# # # early stopping to return the best model\n",
        "# early_stopping = EarlyStopping(monitor='loss', patience=10, verbose=2, restore_best_weights=True, mode='min')\n",
        "# # save the best weights if training is interrupted\n",
        "# mcp_save = ModelCheckpoint('.mdl_wts.hdf5', save_best_only=True, monitor='val_loss', mode='min') \n",
        "# #reduce_lr_loss = ReduceLROnPlateau(monitor='loss', factor=0.1, patience=5, verbose=1, min_delta=1e-4, mode='min')\n",
        "\n",
        "# # Set the initial validation loss to a large value\n",
        "# best_val_loss = float('inf')\n",
        "\n",
        "# # Set the initial and total number of epochs\n",
        "# initial_epoch = 1\n",
        "# n_epochs = 20\n",
        "# loss_tracking = list()\n",
        "\n",
        "# # Run the training loop\n",
        "# for epoch in range(initial_epoch , n_epochs+1):\n",
        "#     print(f'Epoch {epoch}/{n_epochs}')\n",
        "#     # Train the model for one epoch\n",
        "#     history = model.fit(train_X, train_y, callbacks=[early_stopping, mcp_save],\n",
        "#                     epochs=1, batch_size=2, validation_data=(test_X, test_y), verbose=2,\n",
        "#                      shuffle=False)\n",
        "#     # validation loss at each epoch\n",
        "#     validation_loss= model.evaluate(test_X, test_y, verbose=0)\n",
        "#     loss_tracking.append(validation_loss)\n",
        "\n",
        "#     # Save the model every 10 epochs\n",
        "#     if epoch % 10 == 0:\n",
        "#         # Load the best weights\n",
        "#         model.load_weights(f'.mdl_wts.hdf5')\n",
        "#         # Get the validation loss for the best weights\n",
        "#         val_loss = model.evaluate(test_X, test_y, verbose = 0)\n",
        "          \n",
        "#         best_epoch = loss_tracking.index(val_loss) + 1\n",
        "#         # If the validation loss is the best so far, save the model\n",
        "#         if val_loss < best_val_loss:\n",
        "#             # Save the model  in HDF5 foramt with a filename that includes the epoch number\n",
        "#             model.save(f'best_model_{best_epoch}.h5')\n",
        "#             print(f'best_model_{best_epoch}')"
      ],
      "metadata": {
        "id": "RfmgjN3OhMYp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KmrFZTt1Zwr-",
        "outputId": "5655dd19-ca7e-49f3-bdb4-d3c65146923d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learning rate: 9.999999747378752e-05\n",
            "Best weights using early stop 0.003111298196017742 (loss) were saved at epoch 1\n",
            "Best weights using model check point 0.001432529534213245 were saved at epoch 15\n"
          ]
        }
      ],
      "source": [
        "# # Print the learning rate of the optimizer\n",
        "# print(f'Learning rate: {model.optimizer.learning_rate.numpy()}')\n",
        "# # # Check the epoch at which the best weights were saved\n",
        "# print(f'Best weights using early stop {early_stopping.best} (loss) were saved at epoch {(early_stopping.best_epoch +1)}')\n",
        "# # Evaluate the model on the test set\n",
        "# scores = model.evaluate(test_X, test_y, verbose=0)\n",
        "# print(f'Best weights using model check point {scores} were saved at epoch {(best_epoch)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9lKT1sl6ehRW"
      },
      "outputs": [],
      "source": [
        "# 0.00024551700334995985 all variables 6 times steps\n",
        "# 4.2105e-04 all variables 4 times steps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "Om2PkqgiVjri",
        "outputId": "1dde5b38-7670-4c72-9915-d552e750f02c"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1296x432 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "fig, ax = plt.subplots(1, 1, figsize=(18,6)) \n",
        "ax.xaxis.set_major_locator(plt.MultipleLocator(5))\n",
        "#plt.plot(history.history['loss'], label='train')\n",
        "plt.plot(history.history['val_loss'], label='test')\n",
        "plt.legend(fontsize=15)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SHohbk8uYRIh"
      },
      "source": [
        "**MinMax Scaler equation**\n",
        "$$x' = \\frac{(x - min)}{(max - min)} \\times (new\\ max\\ value - new\\ min\\  value) + new\\ min\\ value$$<br/>\n",
        "\n",
        "\n",
        "$$x = \\frac{(max - min)\\times (new\\ min\\ value + x') + (new\\ max\\ value - new\\ min\\ value)\\times min}{new\\ max\\ value - new\\ min\\ value}$$\n",
        "\n",
        "Where:\n",
        "\n",
        "$x$ is the inverse scaled value\n",
        "$x'$ is the scaled value\n",
        "$min$ is the minimum value of the original data\n",
        "$max$ is the maximum value of the original data.<br/>\n",
        "$new\\ max\\ value$ and $new\\ min\\ value$ is the new range that we want to scale the data to. For example: $(1,0)\\ or\\ (1,-1)$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dZ3IIvIhvHaz",
        "outputId": "3536eabe-9775-4fbf-f1b7-79e43a0d023d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12/12 [==============================] - 1s 2ms/step\n"
          ]
        }
      ],
      "source": [
        "# make a prediction \n",
        "# select the number of obersvtions for prediction\n",
        "n_obs = len(test)\n",
        "yhat = model.predict(test_X[-n_obs:], verbose=1)\n",
        "\n",
        "\n",
        "# invert scaling \n",
        "scaled_y = pd.DataFrame(test_y)\n",
        "scaled_yhat = pd.DataFrame(yhat.ravel()) ## ravel () converting into 1D array\n",
        "#obtain the min and max from the training set\n",
        "unscaled_train = pd.DataFrame(series_supervised[:len(train)])\n",
        "#new feature range\n",
        "new_max_value = 1 \n",
        "new_min_value= 0\n",
        "feature_range = new_max_value - new_min_value\n",
        "\n",
        "def transform_column(column):\n",
        "    min_value = min(unscaled_train.iloc[:, -steps_ahead + column.name])\n",
        "    max_value = max(unscaled_train.iloc[:, -steps_ahead + column.name])\n",
        "    return ((max_value - min_value) * (new_min_value + column) + (feature_range  * min_value)) / feature_range \n",
        "    \n",
        "# invert scaling for actual\n",
        "inv_scale_y = scaled_y.apply(transform_column, axis=0)\n",
        "inv_scale_y = inv_scale_y.values.ravel() \n",
        "# invert scaling for forecast\n",
        "inv_scale_yhat = scaled_yhat.apply(transform_column, axis=0)\n",
        "inv_scale_yhat = inv_scale_yhat.values.ravel()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IlNDUcbr52uF",
        "outputId": "35e26049-ec8c-4c84-b361-4181bf06d99d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(368, 7, 12)"
            ]
          },
          "execution_count": 138,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_X[-n_obs:].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "id": "xnZOx0a_8kdZ",
        "outputId": "08fe5165-4de7-4927-d047-4ba5eca72e52"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-dc6fcda9-6894-4bab-b0f7-3fabcade868c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-645.145873</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-436.890244</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-1045.743910</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>51.765141</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1099.836282</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>-159.069310</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>-15913.598207</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>5064.429699</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9587.055113</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2015.758501</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>-362.733377</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>-139.759592</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>-17.359877</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>455.570982</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>-286.437975</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>-120.953058</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>-164.855936</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>259.140197</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>-49.815300</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dc6fcda9-6894-4bab-b0f7-3fabcade868c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-dc6fcda9-6894-4bab-b0f7-3fabcade868c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-dc6fcda9-6894-4bab-b0f7-3fabcade868c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "               0\n",
              "0    -645.145873\n",
              "1    -436.890244\n",
              "2   -1045.743910\n",
              "3      51.765141\n",
              "4    1099.836282\n",
              "5    -159.069310\n",
              "6  -15913.598207\n",
              "7    5064.429699\n",
              "8    9587.055113\n",
              "9    2015.758501\n",
              "10   -362.733377\n",
              "11   -139.759592\n",
              "12    -17.359877\n",
              "13    455.570982\n",
              "14   -286.437975\n",
              "15   -120.953058\n",
              "16   -164.855936\n",
              "17    259.140197\n",
              "18    -49.815300"
            ]
          },
          "execution_count": 81,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd.DataFrame(inv_scale_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "mleqTAENlwZT",
        "outputId": "7c9607c9-88ca-4c54-b8c9-9eade75a49f9"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-dc065745-e606-40d1-a327-03048d3907ee\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3421.333008</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3349.463867</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3328.709961</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3329.249023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3238.881836</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75</th>\n",
              "      <td>2114.317383</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76</th>\n",
              "      <td>2724.540039</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77</th>\n",
              "      <td>2556.254883</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78</th>\n",
              "      <td>1916.452148</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79</th>\n",
              "      <td>-336.940430</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>80 rows  1 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dc065745-e606-40d1-a327-03048d3907ee')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-dc065745-e606-40d1-a327-03048d3907ee button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-dc065745-e606-40d1-a327-03048d3907ee');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "              0\n",
              "0   3421.333008\n",
              "1   3349.463867\n",
              "2   3328.709961\n",
              "3   3329.249023\n",
              "4   3238.881836\n",
              "..          ...\n",
              "75  2114.317383\n",
              "76  2724.540039\n",
              "77  2556.254883\n",
              "78  1916.452148\n",
              "79  -336.940430\n",
              "\n",
              "[80 rows x 1 columns]"
            ]
          },
          "execution_count": 247,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd.DataFrame(inv_scale_yhat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "qLB71nNNbCSg",
        "outputId": "b09c4bb5-2380-470b-9969-c352abce9e98"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-46056847-f1f4-483d-9e7e-66d0d8825ea2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>16090.043945</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>17022.681641</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-46056847-f1f4-483d-9e7e-66d0d8825ea2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-46056847-f1f4-483d-9e7e-66d0d8825ea2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-46056847-f1f4-483d-9e7e-66d0d8825ea2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "              0\n",
              "0  16090.043945\n",
              "1  17022.681641"
            ]
          },
          "execution_count": 607,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd.DataFrame(inv_scale_yhat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "XDNS59TIraW1",
        "outputId": "8fd49eeb-334f-46d6-def7-c77d0d51a91b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-5a218e40-6b7d-46b8-85b7-5819009c81c5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>16130.116211</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>17011.335938</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5a218e40-6b7d-46b8-85b7-5819009c81c5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5a218e40-6b7d-46b8-85b7-5819009c81c5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5a218e40-6b7d-46b8-85b7-5819009c81c5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "              0\n",
              "0  16130.116211\n",
              "1  17011.335938"
            ]
          },
          "execution_count": 566,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd.DataFrame(inv_scale_yhat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TqftbPYxvEE5"
      },
      "outputs": [],
      "source": [
        "# Invert the Differencing for actual \n",
        "df = pd.DataFrame(series.iloc[-len(test)-steps_ahead:,-1])\n",
        "n_vars = df.shape[1]\n",
        "columns = df.columns\n",
        "cols, names = list(), list()\n",
        "for i in range(0, steps_ahead):\n",
        "    cols.append(df.shift(-i))\n",
        "    if i == 0:\n",
        "        names += [('%s(t)' % (columns[j])) for j in range(n_vars)]\n",
        "    else:\n",
        "        names += [('%s(t+%d)' % (columns[j], i)) for j in range(n_vars)]\n",
        "# put it all together\n",
        "agg = pd.concat(cols, axis=1)\n",
        "agg.columns = names\n",
        "agg.dropna(inplace=True)\n",
        "agg = agg.iloc[:-1,0]\n",
        "#drop all the variables that we don't want to predict\n",
        "#agg.drop(columns=vars_to_drop, inplace=True)\n",
        "agg = agg.to_numpy()\n",
        "inv_y = np.add(inv_scale_y,agg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OWAqc4iTkxvn"
      },
      "source": [
        "* To invert the differencing of time series for multistep prediction:<br/>\n",
        "The equation is given by $$\n",
        "\\hat x_{t+h|t}=x_t+(\\widehat{\\Delta x_{t+1}}+\\dots+\\widehat{\\Delta x_{t+h}}).\n",
        "$$ <br/>\n",
        "where: <br/>\n",
        "$\\hat x_{t+h|t}$ is the predicted value of the time series x at time $t$+h, given the value of the time series at time $t$.<br/>\n",
        "$x_t$ is the value of the time series $x$ at time t.<br/>\n",
        "${\\Delta x_{t+1}}$ is the difference between the value of the time series $x$ at time $t+1$ and the value of the time series at time t.<br/>\n",
        "${\\Delta x_{t+2}}$ is the difference between the value of the time series $x$ at time $t+2$ and the value of the time series at time $t+1$.<br/>\n",
        "${\\Delta x_{t+h}}$ is the difference between the value of the time series $x$ at time $t+h$ and the value of the time series at time $t+h-1$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DSJErK0WDkX4"
      },
      "outputs": [],
      "source": [
        "# Invert the Differencing for forecast\n",
        "# to invert the diffrenced predicted values,the the predicted differenced value is added\n",
        "# to previous predicted diffenced values and last available observation in test set(Xt) as explained above\n",
        "originalSeries_supervised = series_to_supervised(series, series.columns, n_in=timesteps, n_out=steps_ahead, dropnan=True)\n",
        "\n",
        "current_timestep = 1\n",
        "# actual value of oil rate at current time step\n",
        "# steps_ahead = 4\n",
        "#drop all the variables that we don't want to predict\n",
        "vars_y = originalSeries_supervised.columns[-steps_ahead*len(series.columns):]\n",
        "vars_to_drop = [col for col in vars_y if col.startswith(vars_name_to_drop[0])]\n",
        "originalSeries_supervised.drop(columns=vars_to_drop, inplace=True)\n",
        "originalSeries_xt = originalSeries_supervised.iloc[-len(test):,-steps_ahead-2]\n",
        "\n",
        "\n",
        "# A predicted value at any given step ahead is a result of the previous cumulative differnced predicted values and current time step\n",
        "col = []\n",
        "#inv_yhat_cum = np.cumsum(inv_scale_yhat, axis=1)\n",
        "inv_yhat_cum = inv_scale_yhat\n",
        "\n",
        "for i in range(n_obs):\n",
        "    #.ravel() flattens the series into a one-dimensional array\n",
        "    inverted_diff_yhat = originalSeries_xt[-n_obs:].ravel()[i] + inv_yhat_cum[i]\n",
        "    col.append(inverted_diff_yhat)\n",
        "#col = pd.DataFrame.from_records(col) # creates a DataFrame from a list of records\n",
        "col = pd.DataFrame(col)\n",
        "#col.columns = pd.RangeIndex(start=1, stop=steps_ahead+1, step=1)\n",
        "inv_yhat = col.values.ravel() # convert df to NumpyArray"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Si8_sP7AeBNV"
      },
      "outputs": [],
      "source": [
        "inv_yhat = np.add(inv_scale_yhat,agg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "alOk-YutHixs",
        "outputId": "f5f6f0fd-9813-4edc-eba5-40d339f05d69"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([3400.90059142, 1902.73060461, 2717.82716026,  672.44365125,\n",
              "         61.70304199, 3062.1313925 , 1036.43499067, 2522.33984681,\n",
              "        885.22794384, 3063.89253947])"
            ]
          },
          "execution_count": 105,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "inv_y[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EUnbXmPJligj",
        "outputId": "f3be5b4e-4418-4713-fc65-a1d5ae5a5291"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([3607.93342036, 2350.85371642, 3257.16322179, 1183.83887901,\n",
              "        126.939745  , 3499.08097167, 1843.84037688, 3750.63127973,\n",
              "       1881.272464  , 3321.59024853])"
            ]
          },
          "execution_count": 106,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "inv_yhat[:10] "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qnEwrbE7dBzK",
        "outputId": "4c98fccd-662d-4804-eee1-7b7aecbcda59"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([3590.59357661, 2211.30977111, 3251.55189367, 1095.77833214,\n",
              "        381.24345593, 3312.50870605, 1757.93412688, 3445.83049848,\n",
              "       1839.522464  , 3686.42227978])"
            ]
          },
          "execution_count": 84,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "inv_yhat[:10] "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PdEkT5sNTIcw",
        "outputId": "34d0d25f-d9f1-44e4-d0e1-f6801687cb59"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([3594.66193598, 2206.2423883 , 3173.63001867, 1143.65919151,\n",
              "        407.15947156, 3368.39737792, 1757.37943938, 3290.52971723,\n",
              "       1995.08789369, 3455.65079541])"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "inv_yhat[:10] "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oJvNG5uGK-CL",
        "outputId": "3f2b8f8e-cf9d-4b5f-8f40-d9098bd95db1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([3626.33967036, 2268.59590392, 3209.46400304, 1201.12501182,\n",
              "        361.57548718, 3662.83683105, 1867.23881438, 3091.02581098,\n",
              "       2142.52344056, 3604.08829541])"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "inv_yhat[:10] "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ksoIwntDr-m",
        "outputId": "8574d814-18b3-4a2e-8c87-038da8de7b5d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([3434.46857661, 3391.58027892, 1893.50794836, 2708.45704307,\n",
              "        663.33622937,   53.39640136, 3052.82279875, 1027.26409223,\n",
              "       2513.01269837,  876.16739697])"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "inv_yhat[:10] "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Cp8I88cA6f_",
        "outputId": "5926c5a5-0758-4344-b082-01a893b0a5db"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([3616.66779536, 2901.4142633 , 2707.84290929, 2021.48536339,\n",
              "        415.11064343, 2041.42862792, 2893.83940032, 1935.12932661,\n",
              "       2185.30762025, 2642.25040478])"
            ]
          },
          "execution_count": 143,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "inv_yhat[:10] "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iU8EPrjW9-WB",
        "outputId": "77946584-1d51-49e0-c189-753a6b043f1d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([3574.35529536, 2202.53340392, 3130.52064367,  958.16505089,\n",
              "          4.90165906, 2767.44425292, 1848.91557219, 3947.85198286,\n",
              "       1786.16992494, 3531.10392041])"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "inv_yhat[:10] "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tm_8nWqG1pv1",
        "outputId": "be20d3f0-c336-4dd2-a218-3f1c7aa15bc0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([3636.01545161, 2339.25898986, 3426.80189367, 1147.14063682,\n",
              "        288.00908093, 3820.93644042, 2009.1470175 , 3904.13713911,\n",
              "       1911.25879212, 3662.91837353])"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "inv_yhat[:10] "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xvxvb4BhFVeh",
        "outputId": "9f0a8759-a30c-4801-9a2f-fbc4b05241c6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([3381.95099848, 1601.08223205, 3568.13392492, -203.34080849,\n",
              "       -564.89033313, 5612.03995605, 2615.65483   , 3544.03557661,\n",
              "       1119.57129212, 3880.51602978])"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "inv_yhat[:10] # 1 time steps # on stream choke"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6CotdhM7B70z",
        "outputId": "6a99acda-ab09-4fd0-b335-e8c6048f31f7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([3362.01447504, 3014.15742736, 1575.44740148, 2900.26856651,\n",
              "        196.33037   ,  969.9657373 , 4537.10893157, 1709.12542036,\n",
              "       2967.28906556, 1227.26407666])"
            ]
          },
          "execution_count": 225,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "inv_yhat[:10] # 4 time steps # on stream choke"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oj0iYlicucxa",
        "outputId": "0c11e428-80fe-425a-bbd8-28da6cbd8a0c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([3357.58478754, 3198.6486383 , 1894.60365148, 2831.45606651,\n",
              "        624.30595593,  780.4735498 , 3790.01518157, 1856.40471723,\n",
              "       3131.147464  , 1301.48477978])"
            ]
          },
          "execution_count": 204,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "inv_yhat[:10]# 4 time steps # on stream"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QA3lZJw-LHgv",
        "outputId": "d0beb942-f44b-4b55-ae68-782911742ce8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.31858047240881304"
            ]
          },
          "execution_count": 108,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "r2_score(inv_y,inv_yhat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8UT3jqDxPF9e",
        "outputId": "12fb85bb-2d64-427c-dbdc-17c7bbe9bc2f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "28.446741757485977"
            ]
          },
          "execution_count": 107,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "wMAPE(inv_y[:10],inv_yhat[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8xw8O7CoPQAG",
        "outputId": "3cdff192-b9ed-42ef-f99f-c96cbd884cab"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((369,), (369,))"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "inv_y.shape, inv_yhat.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nqXWUX41YtDY",
        "outputId": "e3cdcede-ed29-465a-ac7f-70fda875f54a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test RMSE: 449.03130\n",
            "Test RMSPE: 19544194831094544.00000\n",
            "Test MAE: 213.63827\n",
            "Test MAPE: 1353133045674894.00000\n",
            "Test r2: 0.60894\n",
            "Test wMAPE: 9.53361 \n",
            "Test wMAPE: 14.70437 \n"
          ]
        }
      ],
      "source": [
        "# Performance evaluation\n",
        "\n",
        "rmse_test = sqrt(mean_squared_error(inv_y, inv_yhat))\n",
        "print('Test RMSE: %.5f' % rmse_test)\n",
        "#report performance using RMSPE\n",
        "RMSPE_test = RMSPE(inv_y, inv_yhat)\n",
        "print('Test RMSPE: %.5f' % RMSPE_test)\n",
        "MAE_test = mean_absolute_error(inv_y, inv_yhat)\n",
        "print('Test MAE: %.5f' % MAE_test)\n",
        "MAPE_test = MAPE(inv_y, inv_yhat)\n",
        "print('Test MAPE: %.5f' % MAPE_test)\n",
        "r2 = r2_score(inv_y, inv_yhat)\n",
        "print('Test r2: %.5f' % r2)\n",
        "wMAPE_test = wMAPE(inv_y, inv_yhat)\n",
        "print('Test wMAPE: %.5f ' % wMAPE_test)\n",
        "SMAPE_test = SMAPE(inv_y, inv_yhat)\n",
        "print('Test wMAPE: %.5f ' % SMAPE_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "51SnY7n5e0nx",
        "outputId": "1f038602-a51a-4b26-8c5f-0bfb86cabda4"
      },
      "outputs": [
        {
          "ename": "IndexError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-bef913473e92>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mresult_rmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minv_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minv_yhat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mresult_RMSPE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRMSPE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minv_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minv_yhat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mresult_MAE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_absolute_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minv_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minv_yhat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: too many indices for array: array is 1-dimensional, but 2 were indexed"
          ]
        }
      ],
      "source": [
        "# Performance evaluation\n",
        "rmse_test, RMSPE_test, MAE_test, MAPE_test, r2_test, wMAPE_test, SMAPE_test  = [], [], [], [], [], [], []\n",
        "# calculate the score for each day\n",
        "\n",
        "for i in range(test_y.shape[1]):\n",
        "    result_rmse = sqrt(mean_squared_error(inv_y[:,i], inv_yhat[:,i]))\n",
        "    result_RMSPE = RMSPE(inv_y[:,i], inv_yhat[:,i])\n",
        "    result_MAE = mean_absolute_error(inv_y[:,i], inv_yhat[:,i])\n",
        "    result_MAPE = MAPE(inv_y[:,i], inv_yhat[:,i])\n",
        "    result_r2 = r2_score(inv_y[:,i], inv_yhat[:,i])\n",
        "    result_wMAPE = wMAPE(inv_y[:,i], inv_yhat[:,i])\n",
        "    result_SMAPE = SMAPE(inv_y[:,i], inv_yhat[:,i])\n",
        "\n",
        "    rmse_test.append(result_rmse)\n",
        "    RMSPE_test.append(result_RMSPE)\n",
        "    MAE_test.append(result_MAE)\n",
        "    MAPE_test.append(result_MAPE)\n",
        "    r2_test.append(result_r2)\n",
        "    wMAPE_test.append(result_wMAPE)\n",
        "    SMAPE_test.append(result_SMAPE)\n",
        "    \n",
        "## calculate overall score\n",
        "print(\"The Average scores for the vector output {} steps ahead:\\n\".format(steps_ahead))\n",
        "print('Test RMSE: %.5f' % np.mean(rmse_test))\n",
        "#print('Test RMSPE: %.5f' % np.mean(RMSPE_test)) because of that the denominator (actual) has some zero values\n",
        "print('Test MAE: %.5f' % np.mean(MAE_test))\n",
        "#print('Test MAPE: %.5f' % np.mean(MAPE_test)) because of that the denominator (actual) has some zero values\n",
        "print('Test r2: %.5f' % np.mean(r2_test))\n",
        "print('Test wMAPE: %.5f ' % np.mean(wMAPE_test))\n",
        "print('Test SMAPE: %.5f ' % np.mean(SMAPE_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ef--j4gGOE6F"
      },
      "outputs": [],
      "source": [
        "Test RMSE: 555.56135\n",
        "Test MAE: 277.11301\n",
        "Test r2: 0.39641\n",
        "Test wMAPE: 12.32902 \n",
        "Test SMAPE: 17.45901"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H4KkEyXsJvDW"
      },
      "outputs": [],
      "source": [
        "# plot the scores for each time step of the multi-step forecast\n",
        "scores = pd.DataFrame({\"rmse_test\":rmse_test, \"MAE_test\":MAE_test, \"R-squared_test\":r2_test, \"wMAPE_test\":wMAPE_test, \"SMAPE_test\":SMAPE_test})\n",
        "\n",
        "# Reset the index, keeping the old index as a column\n",
        "scores = scores.reset_index(drop=False)\n",
        "\n",
        "# Set the 'index' column as the new index\n",
        "scores.index = scores['index'] + 1\n",
        "\n",
        "# Drop the old 'index' column\n",
        "scores = scores.drop(columns='index')\n",
        "\n",
        "data = scores.columns\n",
        "\n",
        "# Creating figure with two rows and one column\n",
        "fig, axs = plt.subplots(nrows=len(data), figsize=(17, 15))\n",
        "\n",
        "axs = axs.ravel()\n",
        "\n",
        "for id, column in enumerate(data):\n",
        "    # Set the x-axis limits\n",
        "    #axs[id].set_xlim(xmin=1, xmax= steps_ahead)\n",
        "    #print the name of the test on plot\n",
        "    axs[id].plot(scores[column])\n",
        "    # Add a title to the x-axis\n",
        "    axs[id].set_xlabel('Steps ahead',fontsize=10, labelpad=0.1)\n",
        "    axs[id].grid(True)\n",
        "    # Remove the horizontal grid lines\n",
        "    axs[id].grid(which='both', axis='y')\n",
        "    axs[id].xaxis.set_major_locator(plt.MultipleLocator(1))\n",
        "    axs[id].legend([column], loc='upper left', fontsize=15, handlelength=0, handletextpad=0, frameon=False)\n",
        "    \n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w-CDANaINC-c"
      },
      "outputs": [],
      "source": [
        "inv_yhat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iHKnDMnFNdmw"
      },
      "outputs": [],
      "source": [
        "inv_yhat[-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w1S1CN4BEWUe"
      },
      "outputs": [],
      "source": [
        "plt.plot(inv_yhat[-1], label = \"predicted\")\n",
        "plt.plot(inv_y[-1], label = \"actual\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M2CGD3H6NZoj"
      },
      "outputs": [],
      "source": [
        "plt.plot(inv_yhat.flatten(), label = \"predicted\")\n",
        "plt.plot(inv_y.flatten(), label = \"actual\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1GHomhZ5E3jc"
      },
      "outputs": [],
      "source": [
        "plt.plot(inv_yhat.flatten(), label = \"predicted\")\n",
        "plt.plot(inv_y.flatten(), label = \"actual\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "doFyZoCCZ-ht"
      },
      "outputs": [],
      "source": [
        "# plot the last forecasted values on test set\n",
        "fig, ax = plt.subplots(1, 1, figsize=(18,6)) \n",
        "# Set the major locator for the x-axis\n",
        "x = list(range(1, len(inv_yhat[-1])+1))\n",
        "ax.xaxis.set_major_locator(plt.MultipleLocator(1))\n",
        "ax.plot(x, inv_yhat[-1], label = \"predicted\")\n",
        "ax.plot(x, inv_y[-1], label = \"actual\")\n",
        "ax.set_ylabel('Oil Rate', fontsize=15)\n",
        "ax.set_xlabel('Steps Ahead (Days)',fontsize=15)\n",
        "plt.legend(fontsize=15)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zZcZ-O1kL3Q5"
      },
      "outputs": [],
      "source": [
        "#comparing predictions and actual values\n",
        "act_pred = pd.DataFrame({\"actual\":inv_y.flatten(), \"prediction\":inv_yhat.flatten()})\n",
        "act_pred.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7APsQRBRvRbx"
      },
      "outputs": [],
      "source": [
        "series_to_supervised(series, series.columns, n_in=2, n_out=steps_ahead, dropnan=True).iloc[-len(test):-len(test)+5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Kx12S2F506y"
      },
      "outputs": [],
      "source": [
        "r2_score(act_pred.iloc[:5,0],act_pred.iloc[:5,1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vS4cX0QOuinK"
      },
      "outputs": [],
      "source": [
        "wMAPE(act_pred.iloc[:5,0],act_pred.iloc[:5,1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L4g3tcrW5lIB"
      },
      "outputs": [],
      "source": [
        "MAPE(act_pred.iloc[:5,0],act_pred.iloc[:5,1])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "mount_file_id": "1fRyNGg_0mKKrWR0X5NTRjquhMWU9-Gqx",
      "authorship_tag": "ABX9TyNQnO4PQBFUy4TwNAb1Lk6r",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}